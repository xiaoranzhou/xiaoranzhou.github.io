{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmlschema\n",
    "import xml.etree.ElementTree as et \n",
    "import json\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = xmlschema.XMLSchema('checklist/xsd/ENA.project.xsd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = xmlschema.XMLSchema('checklist/xsd/ENA.project.xsd')\n",
    "schema.is_valid('study.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema.validate('study.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = xmlschema.XMLSchema('checklist/SRA.sample.xsd')\n",
    "schema.is_valid('SAMPLE.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema.validate('SAMPLE.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema.validate('test/study.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema.is_valid('test/study.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "xtree = et.parse(\"checklist/ERCs/ERC000037.xml\")\n",
    "xroot = xtree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtree = et.parse(\"checklist/ERCs/ERC000020.xml\")\n",
    "xroot = xtree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtree = et.parse(\"checklist/ERCs/ERC000025.xml\")\n",
    "xroot = xtree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erc_list_name = [\"ERC000020.xml\", \"ERC000035.xml\",\"ERC000037.xml\"]\n",
    "erc_list = [\"checklist/ERCs/ERC000020.xml\", \"checklist/ERCs/ERC000035.xml\",\"checklist/ERCs/ERC000037.xml\"]\n",
    "output_list = []\n",
    "for index, path in enumerate(erc_list):\n",
    "    \n",
    "    xtree = et.parse(path)\n",
    "    xroot = xtree.getroot()\n",
    "    xml_cols = [\"name\", \"label\", \"description\", \"field_type\",\"mandatory\",\"multiplicity\", \"ERC\"]\n",
    "    xml_rows = []\n",
    "\n",
    "    for sets in xroot.iter('FIELD'):\n",
    "        print(sets.find('NAME').text)\n",
    "        r_name = sets.find('NAME').text if sets is not None else None   \n",
    "        r_label = sets.find('LABEL').text if sets is not None else None\n",
    "        r_description = sets.find('DESCRIPTION').text if sets.find('DESCRIPTION') is not None else None      \n",
    "        r_field_type = sets.find('FIELD_TYPE').text if sets is not None else None      \n",
    "        r_mandatory = sets.find('MANDATORY').text if sets is not None else None      \n",
    "        r_multiplicity = sets.find('MULTIPLICITY').text if sets is not None else None   \n",
    "        xml_rows.append([r_name, r_label, r_description, r_field_type, r_mandatory, r_multiplicity,erc_list_name[index] ])    \n",
    "    xml_table= pd.DataFrame(xml_rows, columns= xml_cols)\n",
    "    output_list.append(xml_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_table_37 = xml_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list[0][[\"name\",\"mandatory\"]][output_list[0][[\"name\",\"mandatory\"]][\"mandatory\"]==\"mandatory\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " output_list[2][[\"name\",\"mandatory\"]][output_list[2][[\"name\",\"mandatory\"]][\"mandatory\"]==\"mandatory\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_output2 = output_list[2].set_index('name').join(output_list[0].set_index('name'), lsuffix='_37', rsuffix='_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_output = pd.concat([output_list[0].set_index('name'),output_list[2].set_index('name')])\n",
    "mandatory = all_output[[\"name\",\"mandatory_20\", \"mandatory_37\"]][(all_output[\"mandatory_20\"]==\"mandatory\") |(all_output[\"mandatory_37\"]==\"mandatory\") ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mandatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate =all_output[[\"mandatory_20\", \"mandatory_37\"]][(pd.notna(all_output[\"mandatory_20\"])) &(pd.notna(all_output[\"mandatory_37\"])) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mandatory_20    48\n",
       "mandatory_37    48\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>mandatory_20</th>\n",
       "      <th>mandatory_37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>project name</td>\n",
       "      <td>mandatory</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sequencing method</td>\n",
       "      <td>mandatory</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>collection date</td>\n",
       "      <td>mandatory</td>\n",
       "      <td>mandatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>geographic location (country and/or sea)</td>\n",
       "      <td>mandatory</td>\n",
       "      <td>mandatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>geographic location (latitude)</td>\n",
       "      <td>mandatory</td>\n",
       "      <td>mandatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>geographic location (longitude)</td>\n",
       "      <td>mandatory</td>\n",
       "      <td>mandatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>broad-scale environmental context</td>\n",
       "      <td>mandatory</td>\n",
       "      <td>optional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>local environmental context</td>\n",
       "      <td>mandatory</td>\n",
       "      <td>optional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>environmental medium</td>\n",
       "      <td>mandatory</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>isolation and growth condition</td>\n",
       "      <td>optional</td>\n",
       "      <td>mandatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>plant structure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mandatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>plant developmental stage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mandatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>plant growth medium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mandatory</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         name mandatory_20 mandatory_37\n",
       "0                                project name    mandatory          NaN\n",
       "22                          sequencing method    mandatory          NaN\n",
       "29                            collection date    mandatory    mandatory\n",
       "31   geographic location (country and/or sea)    mandatory    mandatory\n",
       "32             geographic location (latitude)    mandatory    mandatory\n",
       "33            geographic location (longitude)    mandatory    mandatory\n",
       "36          broad-scale environmental context    mandatory     optional\n",
       "37                local environmental context    mandatory     optional\n",
       "38                       environmental medium    mandatory          NaN\n",
       "42             isolation and growth condition     optional    mandatory\n",
       "106                           plant structure          NaN    mandatory\n",
       "107                 plant developmental stage          NaN    mandatory\n",
       "141                       plant growth medium          NaN    mandatory"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_output = pd.merge(output_list[0],output_list[2], on='name',how='outer', suffixes=('_20', '_37'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_37</th>\n",
       "      <th>description_37</th>\n",
       "      <th>field_type_37</th>\n",
       "      <th>mandatory_37</th>\n",
       "      <th>multiplicity_37</th>\n",
       "      <th>ERC_37</th>\n",
       "      <th>label_20</th>\n",
       "      <th>description_20</th>\n",
       "      <th>field_type_20</th>\n",
       "      <th>mandatory_20</th>\n",
       "      <th>multiplicity_20</th>\n",
       "      <th>ERC_20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ploidy</th>\n",
       "      <td>ploidy</td>\n",
       "      <td>The ploidy level of the genome (e.g. allopolyp...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>recommended</td>\n",
       "      <td>single</td>\n",
       "      <td>ERC000037.xml</td>\n",
       "      <td>ploidy</td>\n",
       "      <td>The ploidy level of the genome (e.g. allopolyp...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000020.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number of replicons</th>\n",
       "      <td>number of replicons</td>\n",
       "      <td>Reports the number of replicons in a nuclear g...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>recommended</td>\n",
       "      <td>single</td>\n",
       "      <td>ERC000037.xml</td>\n",
       "      <td>number of replicons</td>\n",
       "      <td>Reports the number of replicons in a nuclear g...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000020.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extrachromosomal elements</th>\n",
       "      <td>extrachromosomal elements</td>\n",
       "      <td>Do plasmids exist of significant phenotypic co...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000037.xml</td>\n",
       "      <td>extrachromosomal elements</td>\n",
       "      <td>Do plasmids exist of significant phenotypic co...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000020.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estimated size</th>\n",
       "      <td>estimated size</td>\n",
       "      <td>The estimated size of the genome (in bp) prior...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>recommended</td>\n",
       "      <td>single</td>\n",
       "      <td>ERC000037.xml</td>\n",
       "      <td>estimated size</td>\n",
       "      <td>The estimated size of the genome (in bp) prior...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000020.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample volume or weight for DNA extraction</th>\n",
       "      <td>sample volume or weight for DNA extraction</td>\n",
       "      <td>Volume (ml) or mass (g) of total collected sam...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>single</td>\n",
       "      <td>ERC000037.xml</td>\n",
       "      <td>sample volume or weight for DNA extraction</td>\n",
       "      <td>Volume (ml) or mass (g) of total collected sam...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000020.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>light regimen</th>\n",
       "      <td>light regimen</td>\n",
       "      <td>information about treatment involving an expos...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>recommended</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000037.xml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biotic regimen</th>\n",
       "      <td>biotic regimen</td>\n",
       "      <td>information about treatment involving use of b...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000037.xml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mechanical damage</th>\n",
       "      <td>mechanical damage</td>\n",
       "      <td>information about any mechanical damage exerte...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000037.xml</td>\n",
       "      <td>mechanical damage</td>\n",
       "      <td>information about any mechanical damage exerte...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000020.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chemical administration</th>\n",
       "      <td>chemical administration</td>\n",
       "      <td>list of chemical compounds administered to the...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000037.xml</td>\n",
       "      <td>chemical administration</td>\n",
       "      <td>list of chemical compounds administered to the...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000020.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perturbation</th>\n",
       "      <td>perturbation</td>\n",
       "      <td>type of perturbation, e.g. chemical administra...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000037.xml</td>\n",
       "      <td>perturbation</td>\n",
       "      <td>type of perturbation, e.g. chemical administra...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000020.xml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              label_37  \\\n",
       "name                                                                                     \n",
       "ploidy                                                                          ploidy   \n",
       "number of replicons                                                number of replicons   \n",
       "extrachromosomal elements                                    extrachromosomal elements   \n",
       "estimated size                                                          estimated size   \n",
       "sample volume or weight for DNA extraction  sample volume or weight for DNA extraction   \n",
       "...                                                                                ...   \n",
       "light regimen                                                            light regimen   \n",
       "biotic regimen                                                          biotic regimen   \n",
       "mechanical damage                                                    mechanical damage   \n",
       "chemical administration                                        chemical administration   \n",
       "perturbation                                                              perturbation   \n",
       "\n",
       "                                                                               description_37  \\\n",
       "name                                                                                            \n",
       "ploidy                                      The ploidy level of the genome (e.g. allopolyp...   \n",
       "number of replicons                         Reports the number of replicons in a nuclear g...   \n",
       "extrachromosomal elements                   Do plasmids exist of significant phenotypic co...   \n",
       "estimated size                              The estimated size of the genome (in bp) prior...   \n",
       "sample volume or weight for DNA extraction  Volume (ml) or mass (g) of total collected sam...   \n",
       "...                                                                                       ...   \n",
       "light regimen                               information about treatment involving an expos...   \n",
       "biotic regimen                              information about treatment involving use of b...   \n",
       "mechanical damage                           information about any mechanical damage exerte...   \n",
       "chemical administration                     list of chemical compounds administered to the...   \n",
       "perturbation                                type of perturbation, e.g. chemical administra...   \n",
       "\n",
       "                                                               field_type_37  \\\n",
       "name                                                                           \n",
       "ploidy                                      \\n                                 \n",
       "number of replicons                         \\n                                 \n",
       "extrachromosomal elements                   \\n                                 \n",
       "estimated size                              \\n                                 \n",
       "sample volume or weight for DNA extraction  \\n                                 \n",
       "...                                                                      ...   \n",
       "light regimen                               \\n                                 \n",
       "biotic regimen                              \\n                                 \n",
       "mechanical damage                           \\n                                 \n",
       "chemical administration                     \\n                                 \n",
       "perturbation                                \\n                                 \n",
       "\n",
       "                                           mandatory_37 multiplicity_37  \\\n",
       "name                                                                      \n",
       "ploidy                                      recommended          single   \n",
       "number of replicons                         recommended          single   \n",
       "extrachromosomal elements                      optional        multiple   \n",
       "estimated size                              recommended          single   \n",
       "sample volume or weight for DNA extraction     optional          single   \n",
       "...                                                 ...             ...   \n",
       "light regimen                               recommended        multiple   \n",
       "biotic regimen                                 optional        multiple   \n",
       "mechanical damage                              optional        multiple   \n",
       "chemical administration                        optional        multiple   \n",
       "perturbation                                   optional        multiple   \n",
       "\n",
       "                                                   ERC_37  \\\n",
       "name                                                        \n",
       "ploidy                                      ERC000037.xml   \n",
       "number of replicons                         ERC000037.xml   \n",
       "extrachromosomal elements                   ERC000037.xml   \n",
       "estimated size                              ERC000037.xml   \n",
       "sample volume or weight for DNA extraction  ERC000037.xml   \n",
       "...                                                   ...   \n",
       "light regimen                               ERC000037.xml   \n",
       "biotic regimen                              ERC000037.xml   \n",
       "mechanical damage                           ERC000037.xml   \n",
       "chemical administration                     ERC000037.xml   \n",
       "perturbation                                ERC000037.xml   \n",
       "\n",
       "                                                                              label_20  \\\n",
       "name                                                                                     \n",
       "ploidy                                                                          ploidy   \n",
       "number of replicons                                                number of replicons   \n",
       "extrachromosomal elements                                    extrachromosomal elements   \n",
       "estimated size                                                          estimated size   \n",
       "sample volume or weight for DNA extraction  sample volume or weight for DNA extraction   \n",
       "...                                                                                ...   \n",
       "light regimen                                                                      NaN   \n",
       "biotic regimen                                                                     NaN   \n",
       "mechanical damage                                                    mechanical damage   \n",
       "chemical administration                                        chemical administration   \n",
       "perturbation                                                              perturbation   \n",
       "\n",
       "                                                                               description_20  \\\n",
       "name                                                                                            \n",
       "ploidy                                      The ploidy level of the genome (e.g. allopolyp...   \n",
       "number of replicons                         Reports the number of replicons in a nuclear g...   \n",
       "extrachromosomal elements                   Do plasmids exist of significant phenotypic co...   \n",
       "estimated size                              The estimated size of the genome (in bp) prior...   \n",
       "sample volume or weight for DNA extraction  Volume (ml) or mass (g) of total collected sam...   \n",
       "...                                                                                       ...   \n",
       "light regimen                                                                             NaN   \n",
       "biotic regimen                                                                            NaN   \n",
       "mechanical damage                           information about any mechanical damage exerte...   \n",
       "chemical administration                     list of chemical compounds administered to the...   \n",
       "perturbation                                type of perturbation, e.g. chemical administra...   \n",
       "\n",
       "                                                               field_type_20  \\\n",
       "name                                                                           \n",
       "ploidy                                      \\n                                 \n",
       "number of replicons                         \\n                                 \n",
       "extrachromosomal elements                   \\n                                 \n",
       "estimated size                              \\n                                 \n",
       "sample volume or weight for DNA extraction  \\n                                 \n",
       "...                                                                      ...   \n",
       "light regimen                                                            NaN   \n",
       "biotic regimen                                                           NaN   \n",
       "mechanical damage                           \\n                                 \n",
       "chemical administration                     \\n                                 \n",
       "perturbation                                \\n                                 \n",
       "\n",
       "                                           mandatory_20 multiplicity_20  \\\n",
       "name                                                                      \n",
       "ploidy                                         optional        multiple   \n",
       "number of replicons                            optional        multiple   \n",
       "extrachromosomal elements                      optional        multiple   \n",
       "estimated size                                 optional        multiple   \n",
       "sample volume or weight for DNA extraction     optional        multiple   \n",
       "...                                                 ...             ...   \n",
       "light regimen                                       NaN             NaN   \n",
       "biotic regimen                                      NaN             NaN   \n",
       "mechanical damage                              optional        multiple   \n",
       "chemical administration                        optional        multiple   \n",
       "perturbation                                   optional        multiple   \n",
       "\n",
       "                                                   ERC_20  \n",
       "name                                                       \n",
       "ploidy                                      ERC000020.xml  \n",
       "number of replicons                         ERC000020.xml  \n",
       "extrachromosomal elements                   ERC000020.xml  \n",
       "estimated size                              ERC000020.xml  \n",
       "sample volume or weight for DNA extraction  ERC000020.xml  \n",
       "...                                                   ...  \n",
       "light regimen                                         NaN  \n",
       "biotic regimen                                        NaN  \n",
       "mechanical damage                           ERC000020.xml  \n",
       "chemical administration                     ERC000020.xml  \n",
       "perturbation                                ERC000020.xml  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Started Reading JSON file\")\n",
    "with open(\"inv.json\", \"r\") as read_file:\n",
    "    print(\"Converting JSON encoded data into Python dictionary\")\n",
    "    arc_json = json.load(read_file)\n",
    "\n",
    "    print(\"Decoded JSON Data From File\")\n",
    "    for key, value in arc_json.items():\n",
    "        print(key, \":\", value)\n",
    "    print(\"Done reading json file\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(np.arange(0,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new function (rewritten)\n",
    "# print(\"Started Reading JSON file\")\n",
    "\n",
    "\n",
    "def append_table_protocol(element, json_rows):\n",
    "\n",
    "    for parameter in element:\n",
    "\n",
    "        p=parameter.get('parameterName') if parameter.get('parameterName') is not None else None\n",
    "#         print(p)\n",
    "        term_name = p.get('annotationValue') if p.get('annotationValue') is not None else None\n",
    "        print('name is: '+ term_name )\n",
    "        term_source = p.get('termSource') if p.get('termSource')  is not None else None\n",
    "        print( term_source)\n",
    "        term_accession = p.get('termAccession') if p.get('termAccession')  is not None else None\n",
    "        print( term_accession)                          \n",
    "        index_value= p.get('comments')[0].get(\"value\")\n",
    "        json_rows.append( [file_id,\n",
    "                           arc_id, \n",
    "                           subsection_id,\n",
    "                           input_id, \n",
    "                           input_name,\n",
    "\n",
    "                           output_id, \n",
    "                           output_name,\n",
    "                           derived_from,\n",
    "                           term_type,\n",
    "                           term_name, \n",
    "                           term_source, \n",
    "                           term_accession, \n",
    "                           index_value, \n",
    "                           value])\n",
    "#         print('index value is: '+ term_value)\n",
    "        \n",
    "\n",
    "\n",
    "def append_table_assays(element, json_rows, option= 1):\n",
    "    \n",
    "    for parameter in element:\n",
    "\n",
    "        c= parameter.get(\"category\")\n",
    "        p=c.get('parameterName') if c.get('parameterName') is not None else None\n",
    "#         print(p)\n",
    "        value = parameter.get('value') if parameter.get('value') is not None else None\n",
    "        term_name = p.get('annotationValue') if p.get('annotationValue') is not None else None\n",
    "#         print('name is: '+ term_name )\n",
    "        term_source = p.get('termSource') if (p.get('termSource') ) is not None else None\n",
    "#         print( term_source)\n",
    "        term_accession = p.get('termAccession') if (p.get('termAccession') ) is not None else None\n",
    "#         print( term_accession)\n",
    "        term_type = \"parameter\"\n",
    "        index_value= p.get('comments')[0].get(\"value\")\n",
    "        \n",
    "        json_rows.append( [file_id, \n",
    "                           arc_id, \n",
    "                           subsection_id,\n",
    "                           input_id, \n",
    "                           input_name,\n",
    "\n",
    "                           output_id, \n",
    "                           output_name,\n",
    "                           derived_from,\n",
    "                           term_type,\n",
    "                           term_name, \n",
    "                           term_source, \n",
    "                           term_accession, \n",
    "                           index_value, \n",
    "                           value])\n",
    "#         print('index value is: '+ term_value)\n",
    "        \n",
    "def append_c_input(element, json_rows):\n",
    "    \n",
    "    for parameter in element:\n",
    "\n",
    "        b = parameter.get(\"category\")\n",
    "        factor = b.get(\"characteristicType\") if b.get(\"characteristicType\") is not None else None\n",
    "#         print(p)\n",
    "        value = parameter.get('value') if parameter.get('value') is not None else None\n",
    "        term_name = factor.get('annotationValue') if factor.get('annotationValue') is not None else None\n",
    "#         print('name is: '+ term_name )\n",
    "        term_source = factor.get('termSource') if (factor.get('termSource') ) is not None else None\n",
    "#         print( term_source)\n",
    "        term_accession = factor.get('termAccession') if (factor.get('termAccession') ) is not None else None\n",
    "#         print( term_accession)\n",
    "        term_type = \"parameter\"\n",
    "        index_value= factor.get('comments')[0].get(\"value\")\n",
    "        json_rows.append( [file_id, \n",
    "                           arc_id, \n",
    "                           subsection_id,\n",
    "                           input_id, \n",
    "                           input_name,\n",
    "\n",
    "                           output_id, \n",
    "                           output_name,\n",
    "                           derived_from,\n",
    "                           term_type,\n",
    "                           term_name, \n",
    "                           term_source, \n",
    "                           term_accession, \n",
    "                           index_value, \n",
    "                           value])\n",
    "#         print('index value is: '+ term_value)\n",
    "\n",
    "def append_input(element, json_rows):\n",
    "    \n",
    "    for parameter in element:\n",
    "\n",
    "        b = parameter.get(\"category\")\n",
    "        factor = b.get(\"factorType\") if b.get(\"factorType\") is not None else None\n",
    "#         print(p)\n",
    "\n",
    "        value = parameter.get('value') if parameter.get('value') is not None else None\n",
    "        term_name = factor.get('annotationValue') if factor.get('annotationValue') is not None else None\n",
    "#         print('name is: '+ term_name )\n",
    "        term_source = factor.get('termSource') if (factor.get('termSource') ) is not None else None\n",
    "#         print( term_source)\n",
    "        term_accession = factor.get('termAccession') if (factor.get('termAccession') ) is not None else None\n",
    "#         print( term_accession)\n",
    "        term_type = \"factor\"\n",
    "        index_value= factor.get('comments')[0].get(\"value\")\n",
    "        json_rows.append( [file_id, \n",
    "                           arc_id, \n",
    "                           subsection_id,\n",
    "                           input_id, \n",
    "                           input_name,\n",
    "\n",
    "                           output_id, \n",
    "                           output_name,\n",
    "                           derived_from,\n",
    "                           term_type,\n",
    "                           term_name, \n",
    "                           term_source, \n",
    "                           term_accession, \n",
    "                           index_value, \n",
    "                           value])\n",
    "#         print('index value is: '+ term_value)\n",
    "\n",
    "def append_output(element, json_rows):\n",
    "    \n",
    "    for parameter in element:\n",
    "        \n",
    "        b = parameter.get(\"category\")\n",
    "        factor = b.get(\"factorType\") if b.get(\"factorType\") is not None else None\n",
    "#         print(p)\n",
    "\n",
    "        value = parameter.get('value') if parameter.get('value') is not None else None\n",
    "        term_name = factor.get('annotationValue') if factor.get('annotationValue') is not None else None\n",
    "#         print('name is: '+ term_name )\n",
    "        term_source = factor.get('termSource') if (factor.get('termSource') ) is not None else None\n",
    "#         print( term_source)\n",
    "        term_accession = factor.get('termAccession') if (factor.get('termAccession') ) is not None else None\n",
    "#         print( term_accession)\n",
    "        term_type = 'factor'\n",
    "        index_value= factor.get('comments')[0].get(\"value\")\n",
    "        json_rows.append( [file_id, \n",
    "                           arc_id, \n",
    "                           subsection_id,\n",
    "                           input_id, \n",
    "                           input_name,\n",
    "\n",
    "                           output_id, \n",
    "                           output_name,\n",
    "                           derived_from,\n",
    "                           term_type,\n",
    "                           term_name, \n",
    "                           term_source, \n",
    "                           term_accession, \n",
    "                           index_value, \n",
    "                           value])\n",
    "#         print('index value is: '+ term_value)\n",
    "#         print('index value is: '+ term_value)\n",
    "# todo factorValues, derived from\n",
    "\n",
    "def init_none():\n",
    "    global input_id \n",
    "    global input_name \n",
    "    global output_id\n",
    "    global output_name \n",
    "    global derived_from \n",
    "    global value \n",
    "    global index_value\n",
    "    global term_type\n",
    "    global term_name\n",
    "    global term_source \n",
    "    global term_accession \n",
    "    input_id = None\n",
    "    input_name = None\n",
    "    output_id = None\n",
    "    output_name = None\n",
    "    derived_from = None\n",
    "    value = None\n",
    "    index_value = None\n",
    "    term_type = None\n",
    "    term_name = None\n",
    "    term_source = None\n",
    "    term_accession = None\n",
    "    \n",
    "def write_smaple_xml(xml_input):\n",
    "    input_ = xml_input[xml_input[\"subsection_id\"].str.match(r'1SPL01_plants_')==True ]\n",
    "    sample= input_\n",
    "    input_list = sample[sample[\"input_name\"].notna()]\n",
    "    output_list = sample[sample[\"output_name\"].notna()]\n",
    "\n",
    "    a = et.Element('SAMPLE_SET')\n",
    "    for i,input_name in enumerate(input_list[\"input_name\"].unique()):\n",
    "        one_sample = sample[sample['input_name'] == input_name]\n",
    "        for i, tags in enumerate(one_sample):\n",
    "            b = et.SubElement(a, 'SAMPLE')\n",
    "\n",
    "            b.attrib = {'alias': input_name , 'center_name':''}\n",
    "            c = et.SubElement(b, 'TITLE')\n",
    "            c.text = one_sample[one_sample['term_name']== 'Organism']['value'].to_string(header=False, index=False)\n",
    "\n",
    "            d = et.SubElement(b, 'SAMPLE_NAME')\n",
    "            d.text = input_name\n",
    "\n",
    "            e = et.SubElement(d, 'TAXON_ID')\n",
    "            e.text = 'id'\n",
    "            f = et.SubElement(d, 'SCIENTIFIC_NAME')\n",
    "            f.text = c.text = one_sample[one_sample['term_name']== 'Organism']['value'].to_string(header=False, index=False)\n",
    "\n",
    "            g = et.SubElement(d, 'COMMON_NAME')\n",
    "            g.text = 'id'\n",
    "\n",
    "            h = et.SubElement(b, 'SAMPLE_ATTRIBUTES')\n",
    "            for index, row in one_sample.iterrows():\n",
    "                i = et.SubElement(h,'SAMPLE_ATTRIBUTE' )\n",
    "                j = et.SubElement(i, 'TAG')\n",
    "                j.text = str(row['term_name'])\n",
    "\n",
    "                k = et.SubElement(i, 'VALUE')\n",
    "                k.text = str(row['value']) \n",
    "\n",
    "\n",
    "    tree = et.ElementTree(a)\n",
    "    et.indent(tree, space=\" \\n\", level=0)\n",
    "    et.dump(a)\n",
    "    tree.write(\"SAMPLE.xml\", encoding=\"utf-8\")\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json():\n",
    "\n",
    "subsection_name = [\"studies\", \"assays\", \"factors\"]\n",
    "\n",
    "\n",
    "protocols =arc_json.get(section)[0].get('protocols')\n",
    "for i, process in enumerate(protocols):\n",
    "    if i > 3:\n",
    "        break\n",
    "    \n",
    "    init_none()\n",
    "    subsection_id = process.get(\"name\")\n",
    "    print(subsection_id)\n",
    "#     subsection = process.get('parameters')\n",
    "#     print(subsection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# new function\n",
    "\n",
    "def convert_json(arc_json_file, mapping_file):\n",
    "    with open(arc_json_file, \"r\") as read_file:\n",
    "#     print(\"Converting JSON encoded data into Python dictionary\")\n",
    "        arc_json = json.load(read_file)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    global file_id\n",
    "    global arc_id\n",
    "    global subsection_id\n",
    "    global input_id \n",
    "    global input_name \n",
    "    global output_id\n",
    "    global output_name \n",
    "    global derived_from \n",
    "    global value \n",
    "    global index_value\n",
    "    global term_type\n",
    "    global term_name\n",
    "    global term_source \n",
    "    global term_accessio\n",
    "    json_table= []\n",
    "    json_cols = [\"file_id\", \n",
    "                 \"arc_id\" , \n",
    "                 \"subsection_id\", \n",
    "                 \"input_id\", \n",
    "                 \"input_name\", \n",
    "\n",
    "                 \"output_id\", \n",
    "                 \"output_name\",\n",
    "                 \"derived_from\",\n",
    "                 \"term_type\",\n",
    "                 \"term_name\", \n",
    "                 \"term_source\", \n",
    "                 \"term_accession\", \n",
    "                 \"index_value\", \n",
    "                 \"value\", ]\n",
    "    json_rows = []\n",
    "    file_id = arc_json.get(\"identifier\")\n",
    "    section = \"studies\"\n",
    "    studies = arc_json.get(\"studies\")\n",
    "\n",
    "    arc_id = studies[0].get(\"identifier\")\n",
    "    processSequences = arc_json.get(\"studies\")[0].get('assays')[0].get(\"processSequence\")\n",
    "\n",
    "    for process_seq in processSequences:\n",
    "\n",
    "        subsection_id = process_seq.get(\"name\")\n",
    "        print(subsection_id)\n",
    "\n",
    "        parameter_values = process_seq.get(\"parameterValues\")\n",
    "        append_table_assays(parameter_values, json_rows)\n",
    "        init_none() \n",
    "        input_section = process_seq.get(\"inputs\")\n",
    "        if input_section != None:\n",
    "    #     print(input_section)\n",
    "            for i,input_ in enumerate(input_section):\n",
    "                input_name = input_.get(\"name\")\n",
    "                input_id = i\n",
    "\n",
    "                derived_from = input_.get(\"derivesFrom\")[0].get(\"name\") if input_.get(\"derivesFrom\") is not None else None\n",
    "                print(input_name + \" derivesFrom is \", derived_from)\n",
    "                characteristics = input_.get(\"characteristics\") \n",
    "                if characteristics != None:\n",
    "                    append_c_input(characteristics,json_rows)\n",
    "                factorvalues = input_.get(\"factorValues\") \n",
    "                if factorvalues != None:\n",
    "                        append_input(factorvalues,json_rows)\n",
    "\n",
    "\n",
    "\n",
    "        init_none()    \n",
    "        output_section = process_seq.get(\"outputs\")\n",
    "\n",
    "    #     print(output_section)\n",
    "        for i, output_ in enumerate(output_section):\n",
    "            output_name = output_.get(\"name\")\n",
    "            output_id = i\n",
    "            derived_from = output_.get(\"derivesFrom\")[0].get(\"name\") if output_.get(\"derivesFrom\") is not None else None\n",
    "            print(output_name + \" and derived from is \", derived_from)\n",
    "\n",
    "            term_type = output_.get('type') if output_.get('type') is not None else None\n",
    "\n",
    "            factorvalues = output_.get(\"factorValues\") \n",
    "            if factorvalues != None:\n",
    "                append_output(factorvalues,json_rows)\n",
    "            else:\n",
    "                json_rows.append( [file_id, \n",
    "                               arc_id, \n",
    "                               subsection_id,\n",
    "                               input_id, \n",
    "                               input_name,\n",
    "\n",
    "                               output_id, \n",
    "                               output_name,\n",
    "                               derived_from,\n",
    "                                   term_type,\n",
    "                               term_name, \n",
    "                               term_source, \n",
    "                               term_accession, \n",
    "                               index_value, \n",
    "                               value])\n",
    "\n",
    "\n",
    "\n",
    "    json_table = pd.DataFrame(json_rows, columns= json_cols)\n",
    "    mapping = pd.read_excel(mapping_file)\n",
    "    term_id = mapping.iloc[:,2]\n",
    "    mapping.iloc[:,3] = term_id.map( lambda x: \"http://purl.obolibrary.org/obo/{}\".format( str(x).replace(\":\", \"_\") )  )\n",
    "\n",
    "    \n",
    "    json_table[\"ena_id\"] = json_table[\"term_name\"]\n",
    "    a = json_table.loc[:, \"ena_id\"]\n",
    "    # a = json_table.loc[:, \"term_accession\"]\n",
    "    term_mapping = mapping.iloc[:,3]\n",
    "    for i, term in enumerate(term_mapping):\n",
    "         cond = json_table[\"term_accession\"] == term\n",
    "    #     print(term)\n",
    "    #     print(filter_)\n",
    "         a.mask(cond , mapping.loc[:, \"Field Name\"][i], inplace= True)\n",
    "    json_table.to_csv('json_table_new.csv')\n",
    "    \n",
    "    \n",
    "    a = et.Element('PROJECT_SET')\n",
    "    for i,project in enumerate(arc_json.get(\"studies\")):\n",
    "        b = et.SubElement(a, 'PROJECT')\n",
    "\n",
    "        b.attrib = {'alias': project.get('identifier')}\n",
    "        c = et.SubElement(b, 'TITLE')\n",
    "        c.text = project.get('title')\n",
    "        d = et.SubElement(b, 'DESCRIPTION')\n",
    "        d.text = str(arc_json.get(\"publications\"))\n",
    "        f = et.SubElement(b, \"SUBMISSION_PROJECT\")\n",
    "        g = et.SubElement(f, \"SEQUENCING_PROJECT\")\n",
    "    tree = et.ElementTree(a)\n",
    "    et.indent(tree, space=\" \\n\", level=0)\n",
    "\n",
    "    tree.write(\"study.xml\", encoding=\"utf-8\")\n",
    "\n",
    "    # sample xml\n",
    "    xml_input = pd.read_csv(\"json_table_new.csv\")\n",
    "    write_smaple_xml(xml_input)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "arc_json_file = 'inv.json'\n",
    "mapping_file = 'mapping_ERC000037.xlsx'\n",
    "convert_json(arc_json_file, mapping_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "json_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_tabble.to_csv(\"save.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pd.read_excel(\"mapping_ERC000037.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_id = mapping.iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mapping.iloc[:,3] = term_id.map( lambda x: \"http://purl.obolibrary.org/obo/{}\".format( str(x).replace(\":\", \"_\") )  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping.to_csv(\"mapping_ERC000037_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ x ==  for x in mapping.iloc[:,3] ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rename some terms based on the ENA template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_table[\"ena_id\"] = json_table[\"term_name\"]\n",
    "a = json_table.loc[:, \"term_accession\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# json_table= []\n",
    "# json_cols = [\"file_id\", \n",
    "#              \"study_id\" , \n",
    "#              \"subsection_id\", \n",
    "#              \"input_id\", \n",
    "#              \"input_name\", \n",
    "\n",
    "#              \"output_id\", \n",
    "#              \"output_name\",\n",
    "#              \"derived_from\",\n",
    "#              \"term_name\", \n",
    "#              \"term_source\", \n",
    "#              \"term_accession\", \n",
    "#              \"index_value\", \n",
    "#              \"value\", ]\n",
    "# json_rows = []\n",
    "# file_id = arc_json.get(\"identifier\")\n",
    "# section = \"studies\"\n",
    "# study_id = arc_json.get(\"studies\")[0].get(\"identifier\")\n",
    "\n",
    "# def append_table_protocol(element):\n",
    "\n",
    "#     for parameter in element:\n",
    "\n",
    "#         p=parameter.get('parameterName') if parameter.get('parameterName') is not None else None\n",
    "# #         print(p)\n",
    "#         term_name = p.get('annotationValue') if p.get('annotationValue') is not None else None\n",
    "#         print('name is: '+ term_name )\n",
    "#         term_source = p.get('termSource') if p.get('termSource')  is not None else None\n",
    "#         print( term_source)\n",
    "#         term_accession = p.get('termAccession') if p.get('termAccession')  is not None else None\n",
    "#         print( term_accession)\n",
    "#         index_value= p.get('comments')[0].get(\"value\")\n",
    "#         json_rows.append( [file_id, \n",
    "#                            study_id, \n",
    "#                            subsection_id,\n",
    "#                            input_id, \n",
    "#                            input_name,\n",
    "\n",
    "#                            output_id, \n",
    "#                            output_name,\n",
    "#                            derived_from,\n",
    "#                            term_name, \n",
    "#                            term_source, \n",
    "#                            term_accession, \n",
    "#                            index_value, \n",
    "#                            value])\n",
    "# #         print('index value is: '+ term_value)\n",
    "        \n",
    "\n",
    "\n",
    "# def append_table_assays(element, option= 1):\n",
    "    \n",
    "#     for parameter in element:\n",
    "\n",
    "#         c= parameter.get(\"category\")\n",
    "#         p=c.get('parameterName') if c.get('parameterName') is not None else None\n",
    "# #         print(p)\n",
    "#         value = c.get('value') if c.get('value') is not None else None\n",
    "#         term_name = p.get('annotationValue') if p.get('annotationValue') is not None else None\n",
    "# #         print('name is: '+ term_name )\n",
    "#         term_source = p.get('termSource') if (p.get('termSource') ) is not None else None\n",
    "# #         print( term_source)\n",
    "#         term_accession = p.get('termAccession') if (p.get('termAccession') ) is not None else None\n",
    "# #         print( term_accession)\n",
    "#         index_value= p.get('comments')[0].get(\"value\")\n",
    "\n",
    "#         json_rows.append( [file_id, \n",
    "#                            study_id, \n",
    "#                            subsection_id,\n",
    "#                            input_id, \n",
    "#                            input_name,\n",
    "\n",
    "#                            output_id, \n",
    "#                            output_name,\n",
    "#                            derived_from,\n",
    "#                            term_name, \n",
    "#                            term_source, \n",
    "#                            term_accession, \n",
    "#                            index_value, \n",
    "#                            value])\n",
    "# #         print('index value is: '+ term_value)\n",
    "        \n",
    "\n",
    "\n",
    "# def append_input(element):\n",
    "    \n",
    "#     for parameter in element:\n",
    "\n",
    "#         b = parameter.get(\"category\")\n",
    "#         p = b.get(\"characteristicType\") if b.get(\"characteristicType\") is not None else None\n",
    "# #         print(p)\n",
    "#         value = b.get('value') if b.get('value') is not None else None\n",
    "#         term_name = p.get('annotationValue') if p.get('annotationValue') is not None else None\n",
    "# #         print('name is: '+ term_name )\n",
    "#         term_source = p.get('termSource') if (p.get('termSource') ) is not None else None\n",
    "# #         print( term_source)\n",
    "#         term_accession = p.get('termAccession') if (p.get('termAccession') ) is not None else None\n",
    "# #         print( term_accession)\n",
    "#         index_value= p.get('comments')[0].get(\"value\")\n",
    "#         json_rows.append( [file_id, \n",
    "#                            study_id, \n",
    "#                            subsection_id,\n",
    "#                            input_id, \n",
    "#                            input_name,\n",
    "\n",
    "#                            output_id, \n",
    "#                            output_name,\n",
    "#                            derived_from,\n",
    "#                            term_name, \n",
    "#                            term_source, \n",
    "#                            term_accession, \n",
    "#                            index_value, \n",
    "#                            value])\n",
    "# #         print('index value is: '+ term_value)\n",
    "\n",
    "\n",
    "\n",
    "# def init_none():\n",
    "#     global input_id \n",
    "#     global input_name \n",
    "#     global output_id\n",
    "#     global output_name \n",
    "#     global derived_from \n",
    "#     global value \n",
    "#     global index_value \n",
    "#     global term_name\n",
    "#     global term_source \n",
    "#     global term_accession \n",
    "#     input_id = None\n",
    "#     input_name = None\n",
    "#     output_id = None\n",
    "#     output_name = None\n",
    "#     derived_from = None\n",
    "#     value = None\n",
    "#     index_value = None\n",
    "#     term_name = None\n",
    "#     term_source = None\n",
    "#     term_accession = None\n",
    "    \n",
    "# def append_output(element):   \n",
    "#     for parameter in element:\n",
    "#         b = parameter.get(\"category\")\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "# protocols =arc_json.get(section)[0].get('protocols')\n",
    "# for i, process in enumerate(protocols):\n",
    "#     if i > 3:\n",
    "#         break\n",
    "    \n",
    "#     init_none()\n",
    "#     subsection_id = process.get(\"name\")\n",
    "#     subsection = process.get('parameters')\n",
    "# #     print(subsection)\n",
    "#     append_table_protocol(subsection)\n",
    "\n",
    "# assays = arc_json.get(section)[0].get('assays')[0].get(\"processSequence\")\n",
    "\n",
    "# for process_seq in assays:\n",
    "#     init_none()\n",
    "    \n",
    "#     subsection_id = process_seq.get(\"name\")\n",
    "#     print(subsection_id)\n",
    "    \n",
    "#     parameter_values = process_seq.get(\"parameterValues\")\n",
    "#     append_table_assays(parameter_values)\n",
    "    \n",
    "#     input_section = process_seq.get(\"inputs\")\n",
    "#     if input_section != None:\n",
    "# #     print(input_section)\n",
    "#         for i,input_ in enumerate(input_section):\n",
    "#             input_name = input_.get(\"name\")\n",
    "#             input_id = i\n",
    "            \n",
    "#             print(input_name)\n",
    "#             derived_from = input_.get(\"derivedFrom\")[0].get(\"name\") if input_.get(\"derivedFrom\") is not None else None\n",
    "#             print(input_name + \" \", derived_from)\n",
    "#             characteristics = input_.get(\"characteristics\") \n",
    "#             if characteristics != None:\n",
    "#                 append_input(characteristics)\n",
    "#             else:\n",
    "#                 json_rows.append( [file_id, \n",
    "#                            study_id, \n",
    "#                            subsection_id,\n",
    "#                            input_id, \n",
    "#                            input_name,\n",
    "\n",
    "#                            output_id, \n",
    "#                            output_name,\n",
    "#                            derived_from,\n",
    "#                            term_name, \n",
    "#                            term_source, \n",
    "#                            term_accession, \n",
    "#                            index_value, \n",
    "#                            value])\n",
    "            \n",
    "#     init_none()    \n",
    "#     output_section = process_seq.get(\"outputs\")\n",
    "\n",
    "# #     print(output_section)\n",
    "#     for output_ in output_section:\n",
    "#         output_name = output_.get(\"name\")\n",
    "#         derived_from = output_.get(\"derivedFrom\")[0].get(\"name\") if output_.get(\"derivedFrom\") is not None else None\n",
    "#         print(output_name + \" \", derived_from)\n",
    "#         characteristics = output_.get(\"characteristics\") \n",
    "#         if characteristics != None:\n",
    "#             append_input(characteristics)\n",
    "#         else:\n",
    "#             json_rows.append( [file_id, \n",
    "#                            study_id, \n",
    "#                            subsection_id,\n",
    "#                            input_id, \n",
    "#                            input_name,\n",
    "\n",
    "#                            output_id, \n",
    "#                            output_name,\n",
    "#                            derived_from,\n",
    "#                            term_name, \n",
    "#                            term_source, \n",
    "#                            term_accession, \n",
    "#                            index_value, \n",
    "#                            value])\n",
    "\n",
    "\n",
    "        \n",
    "# json_table = pd.DataFrame(json_rows, columns= json_cols)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "json_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_table.to_csv(\"save.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assays = arc_json.get(section)[0].get('assays')[0].get(\"processSequence\")\n",
    "\n",
    "for process_seq in assays:\n",
    "    input_id = None\n",
    "    input_name = None\n",
    "    output_id = None\n",
    "    output_name = None\n",
    "\n",
    "    subsection_id = process_seq.get(\"name\")\n",
    "    print(subsection_id)\n",
    "\n",
    "    \n",
    "    input_section = process_seq.get(\"inputs\")\n",
    "#     print(input_section)\n",
    "\n",
    "    append_table(input_section)\n",
    "    output_section = process_seq.get(\"outputs\")\n",
    "    print(output_section)\n",
    "\n",
    "    append_table(output_section)\n",
    "\n",
    "        \n",
    "json_table = pd.DataFrame(json_rows, columns= json_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_json.get(section)[0].get('assays')[0].get(\"processSequence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_process_cols = [\"name\", \"source\", \"accession\", \"value\"]\n",
    "json_process_rows = []\n",
    "sample =arc_json.get('studies')[0].get('assays')[0].get('processSequence') #[0].get('parameterValues')\n",
    "sample\n",
    "# for subset in sample:\n",
    "#     category = subset.get(\"category\")\n",
    "#     p=category.get('parameterName')\n",
    "#     print(p)\n",
    "#     term_name = p.get('annotationValue')\n",
    "# #     print('name is: '+ term_name )\n",
    "#     term_source = p.get('termSource') if (p.get('termSource') ) is not None else None\n",
    "# #     print( term_source)\n",
    "#     term_accession = p.get('termAccession') if (p.get('termAccession') ) is not None else None\n",
    "# #     print( term_accession)\n",
    "#     term_value= p.get('comments')[0].get(\"value\")\n",
    "# #     print('index_value is: '+ term_value)\n",
    "#     value = subset.get('value') if subset.get('value') is not None else None\n",
    "#     print(\"{} is {}\".format( \"the value\" , value ) )\n",
    "#     json_process_rows.append( [term_name, term_source, term_accession, term_value])\n",
    "# json_process_table = pd.DataFrame(json_process_rows, columns= json_process_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_process_cols = [\"name\", \"source\", \"accession\", \"value\"]\n",
    "json_process_rows = []\n",
    "sample =arc_json.get('studies')[0].get('protocols')[0].get('parameters')\n",
    "for parameter in sample:\n",
    "    p=parameter.get('parameterName')\n",
    "    print(p)\n",
    "    term_name = p.get('annotationValue')\n",
    "    print('name is: '+ term_name )\n",
    "    term_source = p.get('termSource') if (p.get('termSource') ) is not None else None\n",
    "    print( term_source)\n",
    "    term_accession = p.get('termAccession') if (p.get('termAccession') ) is not None else None\n",
    "    print( term_accession)\n",
    "    term_value= p.get('comments')[0].get(\"value\")\n",
    "    print('index_value is: '+ term_value)\n",
    "    value = p.get('value') if p.get('value') is not None else None\n",
    "    print(\"{} is {}\".format( \"the value\" , value ) )\n",
    "    json_process_rows.append( [term_name, term_source, term_accession, term_value])\n",
    "json_process_table = pd.DataFrame(json_process_rows, columns= json_process_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_table = pd.read_excel(\"mapping.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "map_mandatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_mandatory =xml_table[xml_table[\"mandatory\"] == \"mandatory\" ]\n",
    "xml_table[xml_table[\"mandatory\"] == \"mandatory\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_table[xml_table[\"mandatory\"] == \"mandatory\" ].to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mandatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mandatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mandatory.replace(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "result = subprocess.run(['curl', \n",
    "                         '-u', \n",
    "                         'Webin-60802:EiZ6VR4H7FzaZDL', \n",
    "                         '-F' ,\n",
    "                         \"SUBMISSION=@./test/submission.xml\", \n",
    "                         '-F', \"PROJECT=@./test/study.xml\", \n",
    "                         \"https://wwwdev.ebi.ac.uk/ena/submit/drop-box/submit/\"], stdout=subprocess.PIPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = et.parse('./template-xmls/submission.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for child in root[0]:\n",
    "    print(child.tag, list(child)[1][0].attrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = et.parse('./template-xmls/study.xml')\n",
    "\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_json.get(\"studies\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [child for child in  root[0]]\n",
    "# root.findall(\"./PROJECT\")[0].set('alias', 'name')\n",
    "# root.findall(\"./PROJECT\")[0].get('alias')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "arc_json = pd.read_csv(\"inv.json\")\n",
    "a = et.Element('PROJECT_SET')\n",
    "for i,project in enumerate(arc_json.get(\"studies\")):\n",
    "    b = et.SubElement(a, 'PROJECT')\n",
    "\n",
    "    b.attrib = {'alias': project.get('identifier')}\n",
    "    c = et.SubElement(b, 'TITLE')\n",
    "    c.text = project.get('title')\n",
    "    d = et.SubElement(b, 'DESCRIPTION')\n",
    "    d.text = str(arc_json.get(\"publications\"))\n",
    "    f = et.SubElement(b, \"SUBMISSION_PROJECT\")\n",
    "    g = et.SubElement(f, \"SEQUENCING_PROJECT\")\n",
    "tree = et.ElementTree(a)\n",
    "et.indent(tree, space=\" \\n\", level=0)\n",
    "\n",
    "tree.write(\"study.xml\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_input = pd.read_csv(\"json_table_new.csv\")\n",
    "input_ = xml_input[xml_input[\"subsection_id\"].str.match(r'1SPL01_plants_')==True ]\n",
    "sample= input_\n",
    "input_list = sample[sample[\"input_name\"].notna()]\n",
    "output_list = sample[sample[\"output_name\"].notna()]\n",
    "\n",
    "input_list[\"input_name\"].unique()\n",
    "output_list[\"output_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,input_name in enumerate(input_list[\"input_name\"].unique()):\n",
    "    one_sample = sample[sample['input_name'] == input_name]\n",
    "    print(one_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list[\"input_name\"].unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample xml\n",
    "xml_input = pd.read_csv(\"json_table_new.csv\")\n",
    "def write_smaple_xml(xml_input):\n",
    "    input_ = xml_input[xml_input[\"subsection_id\"].str.match(r'1SPL01_plants_')==True ]\n",
    "    sample= input_\n",
    "    input_list = sample[sample[\"input_name\"].notna()]\n",
    "    output_list = sample[sample[\"output_name\"].notna()]\n",
    "    \n",
    "    a = et.Element('SAMPLE_SET')\n",
    "    for i,input_name in enumerate(input_list[\"input_name\"].unique()):\n",
    "        one_sample = sample[sample['input_name'] == input_name]\n",
    "        for i, tags in enumerate(one_sample):\n",
    "            b = et.SubElement(a, 'SAMPLE')\n",
    "\n",
    "            b.attrib = {'alias': input_name , 'center_name':''}\n",
    "            c = et.SubElement(b, 'TITLE')\n",
    "            c.text = one_sample[one_sample['term_name']== 'Organism']['value'].to_string(header=False, index=False)\n",
    "\n",
    "            d = et.SubElement(b, 'SAMPLE_NAME')\n",
    "            d.text = input_name\n",
    "\n",
    "            e = et.SubElement(d, 'TAXON_ID')\n",
    "            e.text = 'id'\n",
    "            f = et.SubElement(d, 'SCIENTIFIC_NAME')\n",
    "            f.text = c.text = one_sample[one_sample['term_name']== 'Organism']['value'].to_string(header=False, index=False)\n",
    "\n",
    "            g = et.SubElement(d, 'COMMON_NAME')\n",
    "            g.text = 'id'\n",
    "\n",
    "            h = et.SubElement(b, 'SAMPLE_ATTRIBUTES')\n",
    "            for index, row in one_sample.iterrows():\n",
    "                i = et.SubElement(h,'SAMPLE_ATTRIBUTE' )\n",
    "                j = et.SubElement(i, 'TAG')\n",
    "                j.text = row['term_name']\n",
    "\n",
    "                k = et.SubElement(i, 'VALUE')\n",
    "                k.text = str(row['value']) \n",
    "\n",
    "                \n",
    "    tree = et.ElementTree(a)\n",
    "    et.indent(tree, space=\" \\n\", level=0)\n",
    "    et.dump(a)\n",
    "    tree.write(\"SAMPLE.xml\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#     print(input_)\n",
    "    return input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_smaple_xml(xml_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[(sample[\"input_name\"].isna())& (sample[\"output_name\"].isna()) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_input = pd.read_csv(\"json_table_new.csv\")\n",
    "input_ = xml_input[xml_input[\"subsection_id\"].str.match(r'1SPL01_plants_')==True ]\n",
    "sample= input_\n",
    "input_list = sample[sample[\"input_name\"].notna()]\n",
    "output_list = sample[sample[\"output_name\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_sample = sample[sample['input_name'] == 'DB_097']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_sample[one_sample['term_name']== 'Organism']['value'].to_string(header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(one_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(one_sample['term_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project name\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'tag'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [62]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m r_description \u001b[38;5;241m=\u001b[39m sets\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDESCRIPTION\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mif\u001b[39;00m sets\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDESCRIPTION\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m      \n\u001b[1;32m     16\u001b[0m r_field_type \u001b[38;5;241m=\u001b[39m sets\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFIELD_TYPE\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.//*\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtag \u001b[38;5;28;01mif\u001b[39;00m sets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \n\u001b[0;32m---> 17\u001b[0m r_value_type \u001b[38;5;241m=\u001b[39m \u001b[43msets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFIELD_TYPE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.//*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.//*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtag\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m sets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \n\u001b[1;32m     18\u001b[0m r_mandatory \u001b[38;5;241m=\u001b[39m sets\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMANDATORY\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mif\u001b[39;00m sets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m      \n\u001b[1;32m     19\u001b[0m r_multiplicity \u001b[38;5;241m=\u001b[39m sets\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMULTIPLICITY\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mif\u001b[39;00m sets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m   \n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'tag'"
     ]
    }
   ],
   "source": [
    "erc_list_name = [\"ERC000020.xml\", \"ERC000035.xml\",\"ERC000037.xml\"]\n",
    "erc_list = [\"checklist/ERCs/ERC000020.xml\", \"checklist/ERCs/ERC000035.xml\",\"checklist/ERCs/ERC000037.xml\"]\n",
    "output_list = []\n",
    "for index, path in enumerate(erc_list):\n",
    "    \n",
    "    xtree = et.parse(path)\n",
    "    xroot = xtree.getroot()\n",
    "    xml_cols = [\"name\", \"label\", \"description\", \"field_type\",\"mandatory\",\"multiplicity\", \"ERC\"]\n",
    "    xml_rows = []\n",
    "\n",
    "    for sets in xroot.iter('FIELD'):\n",
    "        print(sets.find('NAME').text)\n",
    "        r_name = sets.find('NAME').text if sets is not None else None   \n",
    "        r_label = sets.find('LABEL').text if sets is not None else None\n",
    "        r_description = sets.find('DESCRIPTION').text if sets.find('DESCRIPTION') is not None else None      \n",
    "        r_field_type = sets.find('FIELD_TYPE').find(\".//*\").tag if sets is not None else None  \n",
    "        r_value_type = sets.find('FIELD_TYPE').find(\".//*\").find(\".//*\").tag if sets.find('FIELD_TYPE').find(\".//*\").find(\".//*\") is not None else None  \n",
    "        r_mandatory = sets.find('MANDATORY').text if sets is not None else None      \n",
    "        r_multiplicity = sets.find('MULTIPLICITY').text if sets is not None else None   \n",
    "        xml_rows.append([r_name, r_label, r_description, r_field_type, r_value_type, r_mandatory, r_multiplicity,erc_list_name[index] ])    \n",
    "    xml_table= pd.DataFrame(xml_rows, columns= xml_cols)\n",
    "    output_list.append(xml_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      TEXT_FIELD\n",
       "1      TEXT_FIELD\n",
       "2      TEXT_FIELD\n",
       "3      TEXT_FIELD\n",
       "4      TEXT_FIELD\n",
       "          ...    \n",
       "97     TEXT_FIELD\n",
       "98     TEXT_FIELD\n",
       "99     TEXT_FIELD\n",
       "100    TEXT_FIELD\n",
       "101    TEXT_FIELD\n",
       "Name: field_type, Length: 102, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_list[0][\"field_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
