{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fe2b0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys, getopt\n",
    "import xml.etree.ElementTree as et \n",
    "import json\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import numpy as np\n",
    "#from pyodide.http import pyfetch\n",
    "#from js import XMLHttpRequest\n",
    "# print(input_json)\n",
    "with open(\"./inv.json\", \"r\") as fh:\n",
    "    input_json  = json.load(fh)\n",
    "\n",
    "input_json = str(input_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d9d330f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Time used for conversion is: 0.27 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "print(\"start\")\n",
    "def append_table_protocol(element, json_rows):\n",
    "\n",
    "    for parameter in element:\n",
    "\n",
    "        p=parameter.get('parameterName') if parameter.get('parameterName') is not None else None\n",
    "#         #  print(p)\n",
    "        term_name = p.get('annotationValue') if p.get('annotationValue') is not None else None\n",
    "        #  print('name is: '+ term_name )\n",
    "        term_source = p.get('termSource') if p.get('termSource')  is not None else None\n",
    "        #  print( term_source)\n",
    "        term_accession = p.get('termAccession') if p.get('termAccession')  is not None else None\n",
    "        #  print( term_accession)                          \n",
    "        index_value= p.get('comments')[0].get(\"value\")\n",
    "        json_rows.append( [file_id,\n",
    "                           arc_id, \n",
    "                           subsection_id,\n",
    "                           input_id, \n",
    "                           input_name,\n",
    "\n",
    "                           output_id, \n",
    "                           output_name,\n",
    "                           derived_from,\n",
    "                           term_type,\n",
    "                           term_name, \n",
    "                           term_source, \n",
    "                           term_accession, \n",
    "                           index_value, \n",
    "                           value])\n",
    "#         print('index value is: '+ term_value)\n",
    "        \n",
    "\n",
    "\n",
    "def append_table_assays(element, json_rows, option= 1):\n",
    "    \n",
    "    for parameter in element:\n",
    "\n",
    "        c= parameter.get(\"category\")\n",
    "        p=c.get('parameterName') if c.get('parameterName') is not None else None\n",
    "#         print(p)\n",
    "        value = parameter.get('value') if parameter.get('value') is not None else None\n",
    "        term_name = p.get('annotationValue') if p.get('annotationValue') is not None else None\n",
    "#         print('name is: '+ term_name )\n",
    "        term_source = p.get('termSource') if (p.get('termSource') ) is not None else None\n",
    "#         print( term_source)\n",
    "        term_accession = p.get('termAccession') if (p.get('termAccession') ) is not None else None\n",
    "#         print( term_accession)\n",
    "        term_type = \"parameter\"\n",
    "        index_value= p.get('comments')[0].get(\"value\")\n",
    "        \n",
    "        json_rows.append( [file_id, \n",
    "                           arc_id, \n",
    "                           subsection_id,\n",
    "                           input_id, \n",
    "                           input_name,\n",
    "\n",
    "                           output_id, \n",
    "                           output_name,\n",
    "                           derived_from,\n",
    "                           term_type,\n",
    "                           term_name, \n",
    "                           term_source, \n",
    "                           term_accession, \n",
    "                           index_value, \n",
    "                           value])\n",
    "#         print('index value is: '+ term_value)\n",
    "        \n",
    "def append_c_input(element, json_rows):\n",
    "    \n",
    "    for parameter in element:\n",
    "\n",
    "        b = parameter.get(\"category\")\n",
    "        factor = b.get(\"characteristicType\") if b.get(\"characteristicType\") is not None else None\n",
    "#         print(p)\n",
    "        value = parameter.get('value') if parameter.get('value') is not None else None\n",
    "        term_name = factor.get('annotationValue') if factor.get('annotationValue') is not None else None\n",
    "#         print('name is: '+ term_name )\n",
    "        term_source = factor.get('termSource') if (factor.get('termSource') ) is not None else None\n",
    "#         print( term_source)\n",
    "        term_accession = factor.get('termAccession') if (factor.get('termAccession') ) is not None else None\n",
    "#         print( term_accession)\n",
    "        term_type = \"parameter\"\n",
    "        index_value= factor.get('comments')[0].get(\"value\")\n",
    "        json_rows.append( [file_id, \n",
    "                           arc_id, \n",
    "                           subsection_id,\n",
    "                           input_id, \n",
    "                           input_name,\n",
    "\n",
    "                           output_id, \n",
    "                           output_name,\n",
    "                           derived_from,\n",
    "                           term_type,\n",
    "                           term_name, \n",
    "                           term_source, \n",
    "                           term_accession, \n",
    "                           index_value, \n",
    "                           value])\n",
    "#         print('index value is: '+ term_value)\n",
    "\n",
    "def append_input(element, json_rows):\n",
    "    \n",
    "    for parameter in element:\n",
    "\n",
    "        b = parameter.get(\"category\")\n",
    "        factor = b.get(\"factorType\") if b.get(\"factorType\") is not None else None\n",
    "#         print(p)\n",
    "\n",
    "        value = parameter.get('value') if parameter.get('value') is not None else None\n",
    "        term_name = factor.get('annotationValue') if factor.get('annotationValue') is not None else None\n",
    "#         print('name is: '+ term_name )\n",
    "        term_source = factor.get('termSource') if (factor.get('termSource') ) is not None else None\n",
    "#         print( term_source)\n",
    "        term_accession = factor.get('termAccession') if (factor.get('termAccession') ) is not None else None\n",
    "#         print( term_accession)\n",
    "        term_type = \"factor\"\n",
    "        index_value= factor.get('comments')[0].get(\"value\")\n",
    "        json_rows.append( [file_id, \n",
    "                           arc_id, \n",
    "                           subsection_id,\n",
    "                           input_id, \n",
    "                           input_name,\n",
    "\n",
    "                           output_id, \n",
    "                           output_name,\n",
    "                           derived_from,\n",
    "                           term_type,\n",
    "                           term_name, \n",
    "                           term_source, \n",
    "                           term_accession, \n",
    "                           index_value, \n",
    "                           value])\n",
    "#         print('index value is: '+ term_value)\n",
    "\n",
    "def append_output(element, json_rows):\n",
    "    \n",
    "    for parameter in element:\n",
    "        \n",
    "        b = parameter.get(\"category\")\n",
    "        factor = b.get(\"factorType\") if b.get(\"factorType\") is not None else None\n",
    "#         print(p)\n",
    "\n",
    "        value = parameter.get('value') if parameter.get('value') is not None else None\n",
    "        term_name = factor.get('annotationValue') if factor.get('annotationValue') is not None else None\n",
    "#         print('name is: '+ term_name )\n",
    "        term_source = factor.get('termSource') if (factor.get('termSource') ) is not None else None\n",
    "#         print( term_source)\n",
    "        term_accession = factor.get('termAccession') if (factor.get('termAccession') ) is not None else None\n",
    "#         print( term_accession)\n",
    "        term_type = 'factor'\n",
    "        index_value= factor.get('comments')[0].get(\"value\")\n",
    "        json_rows.append( [file_id, \n",
    "                           arc_id, \n",
    "                           subsection_id,\n",
    "                           input_id, \n",
    "                           input_name,\n",
    "\n",
    "                           output_id, \n",
    "                           output_name,\n",
    "                           derived_from,\n",
    "                           term_type,\n",
    "                           term_name, \n",
    "                           term_source, \n",
    "                           term_accession, \n",
    "                           index_value, \n",
    "                           value])\n",
    "#         print('index value is: '+ term_value)\n",
    "\n",
    "# todo factorValues, derived from\n",
    "\n",
    "def init_none():\n",
    "    global input_id \n",
    "    global input_name \n",
    "    global output_id\n",
    "    global output_name \n",
    "    global derived_from \n",
    "    global value \n",
    "    global index_value\n",
    "    global term_type\n",
    "    global term_name\n",
    "    global term_source \n",
    "    global term_accession \n",
    "    input_id = None\n",
    "    input_name = None\n",
    "    output_id = None\n",
    "    output_name = None\n",
    "    derived_from = None\n",
    "    value = None\n",
    "    index_value = None\n",
    "    term_type = None\n",
    "    term_name = None\n",
    "    term_source = None\n",
    "    term_accession = None\n",
    "    \n",
    "def write_sample_xml(xml_input):\n",
    "    input_ = xml_input[xml_input[\"subsection_id\"].str.match(r'1SPL01_plants_')==True ]\n",
    "    sample= input_\n",
    "    input_list = sample[sample[\"input_name\"].notna()]\n",
    "    output_list = sample[sample[\"output_name\"].notna()]\n",
    "\n",
    "    a = et.Element('SAMPLE_SET')\n",
    "    for index1,input_name in enumerate(input_list[\"input_name\"].unique()):\n",
    "        one_sample = sample[sample['input_name'] == input_name]\n",
    "        for index2, tags in enumerate(one_sample):\n",
    "            b = et.SubElement(a, 'SAMPLE')\n",
    "\n",
    "            b.attrib = {'alias': input_name , 'center_name':''}\n",
    "            c = et.SubElement(b, 'TITLE')\n",
    "            c.text = one_sample[one_sample['term_name']== 'Organism']['value'].to_string(header=False, index=False)\n",
    "\n",
    "            d = et.SubElement(b, 'SAMPLE_NAME')\n",
    "            #d.text = input_name\n",
    "\n",
    "            e = et.SubElement(d, 'TAXON_ID')\n",
    "            e.text = '110664'\n",
    "            f = et.SubElement(d, 'SCIENTIFIC_NAME')\n",
    "            f.text = c.text = one_sample[one_sample['term_name']== 'Organism']['value'].to_string(header=False, index=False)\n",
    "\n",
    "            g = et.SubElement(d, 'COMMON_NAME')\n",
    "            g.text = input_name\n",
    "\n",
    "            h = et.SubElement(b, 'SAMPLE_ATTRIBUTES')\n",
    "            for index3, row in one_sample.iterrows():\n",
    "                m = et.SubElement(h,'SAMPLE_ATTRIBUTE' )\n",
    "                j = et.SubElement(m, 'TAG')\n",
    "                j.text = str(row['term_name'])\n",
    "\n",
    "                k = et.SubElement(m, 'VALUE')\n",
    "                k.text = str(row['value']) \n",
    "\n",
    "\n",
    "    tree = et.ElementTree(a)\n",
    "    et.indent(tree, space=\" \", level=0)\n",
    "    #et.dump(a)\n",
    "    tree.write(\"SAMPLE.xml\", encoding=\"utf-8\")\n",
    "    return tree\n",
    "        \n",
    "\n",
    "def convert_json(arc_json_file, mapping_file):\n",
    "    with open(arc_json_file, \"r\") as read_file:\n",
    "#     print(\"Converting JSON encoded data into Python dictionary\")\n",
    "        arc_json = json.load(read_file)\n",
    "    \n",
    "    \n",
    "\n",
    "    global xml_output\n",
    "    global xmloutput\n",
    "    global file_id\n",
    "    global arc_id\n",
    "    global subsection_id\n",
    "    global input_id \n",
    "    global input_name \n",
    "    global output_id\n",
    "    global output_name \n",
    "    global derived_from \n",
    "    global value \n",
    "    global index_value\n",
    "    global term_type\n",
    "    global term_name\n",
    "    global term_source \n",
    "    global term_accessio\n",
    "    json_table= []\n",
    "    json_cols = [\"file_id\", \n",
    "                 \"arc_id\" , \n",
    "                 \"subsection_id\", \n",
    "                 \"input_id\", \n",
    "                 \"input_name\", \n",
    "\n",
    "                 \"output_id\", \n",
    "                 \"output_name\",\n",
    "                 \"derived_from\",\n",
    "                 \"term_type\",\n",
    "                 \"term_name\", \n",
    "                 \"term_source\", \n",
    "                 \"term_accession\", \n",
    "                 \"index_value\", \n",
    "                 \"value\", ]\n",
    "    json_rows = []\n",
    "    init_none()\n",
    "    file_id = arc_json.get(\"identifier\")\n",
    "    section = \"studies\"\n",
    "    studies = arc_json.get(\"studies\")\n",
    "    arc_id = studies[0].get(\"identifier\")\n",
    "    processSequences = arc_json.get(\"studies\")[0].get('assays')[0].get(\"processSequence\")\n",
    "\n",
    "    for process_seq in processSequences:\n",
    "\n",
    "        subsection_id = process_seq.get(\"name\")\n",
    "        #  print(subsection_id)\n",
    "\n",
    "        parameter_values = process_seq.get(\"parameterValues\")\n",
    "        append_table_assays(parameter_values, json_rows)\n",
    "        init_none() \n",
    "        input_section = process_seq.get(\"inputs\")\n",
    "        if input_section != None:\n",
    "    #     print(input_section)\n",
    "            for i,input_ in enumerate(input_section):\n",
    "                input_name = input_.get(\"name\")\n",
    "                input_id = i\n",
    "\n",
    "                derived_from = input_.get(\"derivesFrom\")[0].get(\"name\") if input_.get(\"derivesFrom\") is not None else None\n",
    "                #  print(input_name + \" derivesFrom is \", derived_from)\n",
    "                characteristics = input_.get(\"characteristics\") \n",
    "                if characteristics != None:\n",
    "                    append_c_input(characteristics,json_rows)\n",
    "                factorvalues = input_.get(\"factorValues\") \n",
    "                if factorvalues != None:\n",
    "                        append_input(factorvalues,json_rows)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "        output_section = process_seq.get(\"outputs\")\n",
    "\n",
    "    #     print(output_section)\n",
    "        for i, output_ in enumerate(output_section):\n",
    "            output_name = output_.get(\"name\")\n",
    "            output_id = i\n",
    "            derived_from = output_.get(\"derivesFrom\")[0].get(\"name\") if output_.get(\"derivesFrom\") is not None else None\n",
    "            #  print(output_name + \" and derived from is \", derived_from)\n",
    "\n",
    "            term_type = output_.get('type') if output_.get('type') is not None else None\n",
    "\n",
    "            factorvalues = output_.get(\"factorValues\") \n",
    "            if factorvalues != None:\n",
    "                append_output(factorvalues,json_rows)\n",
    "            else:\n",
    "                json_rows.append( [file_id, \n",
    "                               arc_id, \n",
    "                               subsection_id,\n",
    "                               input_id, \n",
    "                               input_name,\n",
    "\n",
    "                               output_id, \n",
    "                               output_name,\n",
    "                               derived_from,\n",
    "                                   term_type,\n",
    "                               term_name, \n",
    "                               term_source, \n",
    "                               term_accession, \n",
    "                               index_value, \n",
    "                               value])\n",
    "\n",
    "\n",
    "\n",
    "    json_table = pd.DataFrame(json_rows, columns= json_cols)\n",
    "    mapping = pd.read_csv(mapping_file)\n",
    "    term_id = mapping.iloc[:,2]\n",
    "    mapping.iloc[:,3] = term_id.map( lambda x: \"http://purl.obolibrary.org/obo/{}\".format( str(x).replace(\":\", \"_\") )  )\n",
    "\n",
    "    \n",
    "    json_table[\"ena_id\"] = json_table[\"term_name\"]\n",
    "    a = json_table.loc[:, \"ena_id\"]\n",
    "    # a = json_table.loc[:, \"term_accession\"]\n",
    "    term_mapping = mapping.iloc[:,3]\n",
    "    for i, term in enumerate(term_mapping):\n",
    "         cond = json_table[\"term_accession\"] == term\n",
    "    #     print(term)\n",
    "    #     print(filter_)\n",
    "         a.mask(cond , mapping.loc[:, \"Field Name\"][i], inplace= True)\n",
    "    json_table.to_csv('json_table_new.csv')\n",
    "    \n",
    "    \n",
    "    a = et.Element('PROJECT_SET')\n",
    "    for i,project in enumerate(arc_json.get(\"studies\")):\n",
    "        b = et.SubElement(a, 'PROJECT')\n",
    "\n",
    "        b.attrib = {'alias': project.get('identifier')}\n",
    "        c = et.SubElement(b, 'TITLE')\n",
    "        c.text = project.get('title')\n",
    "        d = et.SubElement(b, 'DESCRIPTION')\n",
    "        d.text = str(arc_json.get(\"publications\"))\n",
    "        f = et.SubElement(b, \"SUBMISSION_PROJECT\")\n",
    "        g = et.SubElement(f, \"SEQUENCING_PROJECT\")\n",
    "    tree = et.ElementTree(a)\n",
    "    et.indent(tree, space=\" \", level=0)\n",
    "\n",
    "    tree.write(\"STUDY.xml\", encoding=\"utf-8\")\n",
    "\n",
    "    # sample xml\n",
    "    xml_input = pd.read_csv(\"json_table_new.csv\")\n",
    "    xml_output = et.tostring(write_sample_xml(xml_input).getroot(), encoding='utf8', method='xml')\n",
    "    xmloutput = xml_output.decode(\"utf-8\")\n",
    "    with open(\"SAMPLE.XML\", \"wb\") as fh:\n",
    "        fh.write(xml_output )\n",
    "    \n",
    "#req1 = XMLHttpRequest.new()\n",
    "#req1.open(\"GET\", \"./inv.json\", False)\n",
    "#req1.send(None)\n",
    "#arc_json_file = str(req1.response)\n",
    "# with open(\"inv.json\", \"w\") as fh:\n",
    "#       fh.write(input_json)\n",
    "\n",
    "# req2 = XMLHttpRequest.new()\n",
    "# req2.open(\"GET\", \"./mapping_ERC000037.csv\", False)\n",
    "# req2.send(None)\n",
    "# mapping_file = str(req2.response)\n",
    "# with open(\"mapping_ERC000037.csv\", \"w\") as fh:\n",
    "#       fh.write(mapping_file)\n",
    "\n",
    "\n",
    "#req3 = XMLHttpRequest.new()\n",
    "#req3.open(\"GET\", \"./json_table_new.csv\", False)\n",
    "#req3.send(None)\n",
    "#json_table_new = str(req3.response)\n",
    "#with open(\"json_table_new.csv\", \"w\") as fh:\n",
    "#      fh.write(json_table_new)\n",
    "\n",
    "convert_json(\"inv.json\", \"mapping_ERC000037.csv\")\n",
    "end = time.time()\n",
    "used_time = end - start\n",
    "print(\"Time used for conversion is: {} seconds\".format(round(used_time, 2)) )\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0b58706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_json_file = \"inv.json\"\n",
    "mapping_file=\"mapping_ERC000037.csv\"\n",
    "with open(arc_json_file, \"r\") as read_file:\n",
    "#     print(\"Converting JSON encoded data into Python dictionary\")\n",
    "    arc_json = json.load(read_file)\n",
    "\n",
    "\n",
    "\n",
    "global xml_output\n",
    "global xmloutput\n",
    "global file_id\n",
    "global arc_id\n",
    "global subsection_id\n",
    "global input_id \n",
    "global input_name \n",
    "global output_id\n",
    "global output_name \n",
    "global derived_from \n",
    "global value \n",
    "global index_value\n",
    "global term_type\n",
    "global term_name\n",
    "global term_source \n",
    "global term_accessio\n",
    "json_table= []\n",
    "json_cols = [\"file_id\", \n",
    "             \"arc_id\" , \n",
    "             \"subsection_id\", \n",
    "             \"input_id\", \n",
    "             \"input_name\", \n",
    "\n",
    "             \"output_id\", \n",
    "             \"output_name\",\n",
    "             \"derived_from\",\n",
    "             \"term_type\",\n",
    "             \"term_name\", \n",
    "             \"term_source\", \n",
    "             \"term_accession\", \n",
    "             \"index_value\", \n",
    "             \"value\", ]\n",
    "json_rows = []\n",
    "init_none()\n",
    "file_id = arc_json.get(\"identifier\")\n",
    "section = \"studies\"\n",
    "studies = arc_json.get(\"studies\")\n",
    "arc_id = studies[0].get(\"identifier\")\n",
    "processSequences = arc_json.get(\"studies\")[0].get('assays')[0].get(\"processSequence\")\n",
    "\n",
    "for process_seq in processSequences:\n",
    "\n",
    "    subsection_id = process_seq.get(\"name\")\n",
    "    #  print(subsection_id)\n",
    "\n",
    "    parameter_values = process_seq.get(\"parameterValues\")\n",
    "    append_table_assays(parameter_values, json_rows)\n",
    "    init_none() \n",
    "    input_section = process_seq.get(\"inputs\")\n",
    "    if input_section != None:\n",
    "#     print(input_section)\n",
    "        for i,input_ in enumerate(input_section):\n",
    "            input_name = input_.get(\"name\")\n",
    "            input_id = i\n",
    "\n",
    "            derived_from = input_.get(\"derivesFrom\")[0].get(\"name\") if input_.get(\"derivesFrom\") is not None else None\n",
    "            #  print(input_name + \" derivesFrom is \", derived_from)\n",
    "            characteristics = input_.get(\"characteristics\") \n",
    "            if characteristics != None:\n",
    "                append_c_input(characteristics,json_rows)\n",
    "            factorvalues = input_.get(\"factorValues\") \n",
    "            if factorvalues != None:\n",
    "                    append_input(factorvalues,json_rows)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    output_section = process_seq.get(\"outputs\")\n",
    "\n",
    "#     print(output_section)\n",
    "    for i, output_ in enumerate(output_section):\n",
    "        output_name = output_.get(\"name\")\n",
    "        output_id = i\n",
    "        derived_from = output_.get(\"derivesFrom\")[0].get(\"name\") if output_.get(\"derivesFrom\") is not None else None\n",
    "        #  print(output_name + \" and derived from is \", derived_from)\n",
    "\n",
    "        term_type = output_.get('type') if output_.get('type') is not None else None\n",
    "\n",
    "        factorvalues = output_.get(\"factorValues\") \n",
    "        if factorvalues != None:\n",
    "            append_output(factorvalues,json_rows)\n",
    "        else:\n",
    "            json_rows.append( [file_id, \n",
    "                           arc_id, \n",
    "                           subsection_id,\n",
    "                           input_id, \n",
    "                           input_name,\n",
    "\n",
    "                           output_id, \n",
    "                           output_name,\n",
    "                           derived_from,\n",
    "                               term_type,\n",
    "                           term_name, \n",
    "                           term_source, \n",
    "                           term_accession, \n",
    "                           index_value, \n",
    "                           value])\n",
    "\n",
    "\n",
    "\n",
    "json_table = pd.DataFrame(json_rows, columns= json_cols)\n",
    "mapping = pd.read_csv(mapping_file)\n",
    "term_id = mapping.iloc[:,2]\n",
    "mapping.iloc[:,3] = term_id.map( lambda x: \"http://purl.obolibrary.org/obo/{}\".format( str(x).replace(\":\", \"_\") )  )\n",
    "\n",
    "json_table[\"in_ena\"] = False\n",
    "json_table[\"ena_id\"] = json_table[\"term_name\"]\n",
    "\n",
    "a = json_table.loc[:, \"ena_id\"]\n",
    "b = json_table.loc[:, \"in_ena\"]\n",
    "# a = json_table.loc[:, \"term_accession\"]\n",
    "term_mapping = mapping.iloc[:,3]\n",
    "for i, term in enumerate(term_mapping):\n",
    "    cond = json_table[\"term_accession\"] == term\n",
    "#     print(term)\n",
    "#     print(filter_)\n",
    "    a.mask(cond , mapping.loc[:, \"Field Name\"][i], inplace= True)\n",
    "    b.mask(cond , mapping.loc[:, \"Requirement\"][i], inplace= True)\n",
    "json_table.to_csv('json_table_new.csv')\n",
    "\n",
    "\n",
    "a = et.Element('PROJECT_SET')\n",
    "for i,project in enumerate(arc_json.get(\"studies\")):\n",
    "    b = et.SubElement(a, 'PROJECT')\n",
    "\n",
    "    b.attrib = {'alias': project.get('identifier')}\n",
    "    c = et.SubElement(b, 'TITLE')\n",
    "    c.text = project.get('title')\n",
    "    d = et.SubElement(b, 'DESCRIPTION')\n",
    "    d.text = str(arc_json.get(\"publications\"))\n",
    "    f = et.SubElement(b, \"SUBMISSION_PROJECT\")\n",
    "    g = et.SubElement(f, \"SEQUENCING_PROJECT\")\n",
    "tree = et.ElementTree(a)\n",
    "et.indent(tree, space=\" \", level=0)\n",
    "\n",
    "tree.write(\"STUDY.xml\", encoding=\"utf-8\")\n",
    "\n",
    "# sample xml\n",
    "xml_input = pd.read_csv(\"json_table_new.csv\")\n",
    "xml_output = et.tostring(write_sample_xml(xml_input).getroot(), encoding='utf8', method='xml')\n",
    "xmloutput = xml_output.decode(\"utf-8\")\n",
    "with open(\"SAMPLE.XML\", \"wb\") as fh:\n",
    "    fh.write(xml_output )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2d680895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         False\n",
       "1         False\n",
       "2      optional\n",
       "3         False\n",
       "4      optional\n",
       "         ...   \n",
       "304       False\n",
       "305       False\n",
       "306       False\n",
       "307       False\n",
       "308       False\n",
       "Name: in_ena, Length: 309, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_table[\"in_ena\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4cd5d5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>arc_id</th>\n",
       "      <th>subsection_id</th>\n",
       "      <th>input_id</th>\n",
       "      <th>input_name</th>\n",
       "      <th>output_id</th>\n",
       "      <th>output_name</th>\n",
       "      <th>derived_from</th>\n",
       "      <th>term_type</th>\n",
       "      <th>term_name</th>\n",
       "      <th>term_source</th>\n",
       "      <th>index_value</th>\n",
       "      <th>value</th>\n",
       "      <th>in_ena</th>\n",
       "      <th>ena_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_accession</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>http://purl.obolibrary.org/obo/NFDI4PSO_0000009</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.obolibrary.org/obo/NFDI4PSO_0000011</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.obolibrary.org/obo/NFDI4PSO_0000030</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.obolibrary.org/obo/NFDI4PSO_0000031</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.obolibrary.org/obo/NFDI4PSO_0000065</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.obolibrary.org/obo/NFDI4PSO_0000071</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.obolibrary.org/obo/NFDI4PSO_0000072</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.obolibrary.org/obo/NFDI4PSO_0000073</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.obolibrary.org/obo/NFDI4PSO_0000074</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.obolibrary.org/obo/NFDI4PSO_0000075</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.obolibrary.org/obo/NFDI4PSO_0000076</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.obolibrary.org/obo/PECO_0007147</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.obolibrary.org/obo/PECO_0007383</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.obolibrary.org/obo/TO_1000012</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 file_id  arc_id  \\\n",
       "term_accession                                                     \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000009        1       1   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000011        1       1   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000030        6       6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000031        6       6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000065        6       6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000071        6       6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000072        6       6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000073        6       6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000074        6       6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000075        6       6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000076        6       6   \n",
       "http://purl.obolibrary.org/obo/PECO_0007147            6       6   \n",
       "http://purl.obolibrary.org/obo/PECO_0007383            6       6   \n",
       "http://purl.obolibrary.org/obo/TO_1000012              6       6   \n",
       "\n",
       "                                                 subsection_id  input_id  \\\n",
       "term_accession                                                             \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000009              1         0   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000011              1         0   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000030              6         6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000031              6         6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000065              6         6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000071              6         6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000072              6         6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000073              6         6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000074              6         6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000075              6         6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000076              6         6   \n",
       "http://purl.obolibrary.org/obo/PECO_0007147                  6         6   \n",
       "http://purl.obolibrary.org/obo/PECO_0007383                  6         6   \n",
       "http://purl.obolibrary.org/obo/TO_1000012                    6         6   \n",
       "\n",
       "                                                 input_name  output_id  \\\n",
       "term_accession                                                           \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000009           0          0   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000011           0          0   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000030           6          0   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000031           6          0   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000065           6          0   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000071           6          0   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000072           6          0   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000073           6          0   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000074           6          0   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000075           6          0   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000076           6          0   \n",
       "http://purl.obolibrary.org/obo/PECO_0007147               6          0   \n",
       "http://purl.obolibrary.org/obo/PECO_0007383               6          0   \n",
       "http://purl.obolibrary.org/obo/TO_1000012                 6          0   \n",
       "\n",
       "                                                 output_name  derived_from  \\\n",
       "term_accession                                                               \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000009            0             0   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000011            0             0   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000030            0             0   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000031            0             0   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000065            0             0   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000071            0             0   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000072            0             0   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000073            0             0   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000074            0             0   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000075            0             0   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000076            0             0   \n",
       "http://purl.obolibrary.org/obo/PECO_0007147                0             0   \n",
       "http://purl.obolibrary.org/obo/PECO_0007383                0             0   \n",
       "http://purl.obolibrary.org/obo/TO_1000012                  0             0   \n",
       "\n",
       "                                                 term_type  term_name  \\\n",
       "term_accession                                                          \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000009          1          1   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000011          1          1   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000030          6          6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000031          6          6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000065          6          6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000071          6          6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000072          6          6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000073          6          6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000074          6          6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000075          6          6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000076          6          6   \n",
       "http://purl.obolibrary.org/obo/PECO_0007147              6          6   \n",
       "http://purl.obolibrary.org/obo/PECO_0007383              6          6   \n",
       "http://purl.obolibrary.org/obo/TO_1000012                6          6   \n",
       "\n",
       "                                                 term_source  index_value  \\\n",
       "term_accession                                                              \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000009            1            1   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000011            1            1   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000030            6            6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000031            6            6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000065            6            6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000071            6            6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000072            6            6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000073            6            6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000074            6            6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000075            6            6   \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000076            6            6   \n",
       "http://purl.obolibrary.org/obo/PECO_0007147                6            6   \n",
       "http://purl.obolibrary.org/obo/PECO_0007383                6            6   \n",
       "http://purl.obolibrary.org/obo/TO_1000012                  6            6   \n",
       "\n",
       "                                                 value  in_ena  ena_id  \n",
       "term_accession                                                          \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000009      0       1       1  \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000011      0       1       1  \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000030      6       6       6  \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000031      0       6       6  \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000065      0       6       6  \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000071      0       6       6  \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000072      0       6       6  \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000073      0       6       6  \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000074      0       6       6  \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000075      0       6       6  \n",
       "http://purl.obolibrary.org/obo/NFDI4PSO_0000076      0       6       6  \n",
       "http://purl.obolibrary.org/obo/PECO_0007147          6       6       6  \n",
       "http://purl.obolibrary.org/obo/PECO_0007383          6       6       6  \n",
       "http://purl.obolibrary.org/obo/TO_1000012            0       6       6  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_table[json_table[\"in_ena\"]!=False].groupby(['term_accession']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3a6645c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['http://purl.obolibrary.org/obo/NFDI4PSO_0000065',\n",
       "  'http://purl.obolibrary.org/obo/NFDI4PSO_0000075',\n",
       "  'http://purl.obolibrary.org/obo/PECO_0007147'],\n",
       " ['Isolate', 'Sample Collection Date', 'plant growth medium exposure'],\n",
       " ['http://purl.obolibrary.org/obo/NFDI4PSO_0000030',\n",
       "  'http://purl.obolibrary.org/obo/NFDI4PSO_0000071',\n",
       "  'http://purl.obolibrary.org/obo/PECO_0007383'],\n",
       " ['Organism', 'Plant disease', 'watering exposure'],\n",
       " ['http://purl.obolibrary.org/obo/NFDI4PSO_0000009',\n",
       "  'http://purl.obolibrary.org/obo/NFDI4PSO_0000011',\n",
       "  'http://purl.obolibrary.org/obo/NFDI4PSO_0000031',\n",
       "  'http://purl.obolibrary.org/obo/NFDI4PSO_0000072',\n",
       "  'http://purl.obolibrary.org/obo/NFDI4PSO_0000073',\n",
       "  'http://purl.obolibrary.org/obo/NFDI4PSO_0000074',\n",
       "  'http://purl.obolibrary.org/obo/NFDI4PSO_0000076',\n",
       "  'http://purl.obolibrary.org/obo/TO_1000012'],\n",
       " ['Genotype',\n",
       "  'Geographic Area',\n",
       "  'Phenotype',\n",
       "  'Plant disease stage',\n",
       "  'Sample Collected By',\n",
       "  'Sample Collection Method',\n",
       "  'Sample storage',\n",
       "  'whole plant size']]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(json_table[json_table[\"in_ena\"]==\"mandatory\"].groupby(['term_accession']).count().index),\n",
    "list(json_table[json_table[\"in_ena\"]==\"mandatory\"].groupby(['term_name']).count().index),\n",
    "list(json_table[json_table[\"in_ena\"]==\"recommended\"].groupby(['term_accession']).count().index),\n",
    "list(json_table[json_table[\"in_ena\"]==\"recommended\"].groupby(['term_name']).count().index),\n",
    "list(json_table[json_table[\"in_ena\"]==\"optional\"].groupby(['term_accession']).count().index),\n",
    "list(json_table[json_table[\"in_ena\"]==\"optional\"].groupby(['term_name']).count().index),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "31f7039c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 37,  72, 107, 142, 177, 212]),)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(json_table[\"term_accession\"] == 'http://purl.obolibrary.org/obo/NFDI4PSO_0000076')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e51204d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= json_table[\"term_accession\"] == 'http://purl.obolibrary.org/obo/NFDI4PSO_0000076'\n",
    "a[37]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
