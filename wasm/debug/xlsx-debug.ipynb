{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmlschema\n",
    "import xml.etree.ElementTree as et \n",
    "import json\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.2\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = xmlschema.XMLSchema('checklist/xsd/ENA.project.xsd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = xmlschema.XMLSchema('checklist/xsd/ENA.project.xsd')\n",
    "schema.is_valid('study.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema.validate('study.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = xmlschema.XMLSchema('checklist/SRA.sample.xsd')\n",
    "schema.is_valid('SAMPLE.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema.validate('SAMPLE.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema.validate('test/study.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema.is_valid('test/study.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "xtree = et.parse(\"checklist/ERCs/ERC000037.xml\")\n",
    "xroot = xtree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtree = et.parse(\"checklist/ERCs/ERC000020.xml\")\n",
    "xroot = xtree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtree = et.parse(\"checklist/ERCs/ERC000025.xml\")\n",
    "xroot = xtree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erc_list_name = [\"ERC000020.xml\", \"ERC000035.xml\",\"ERC000037.xml\"]\n",
    "erc_list = [\"checklist/ERCs/ERC000020.xml\", \"checklist/ERCs/ERC000035.xml\",\"checklist/ERCs/ERC000037.xml\"]\n",
    "output_list = []\n",
    "for index, path in enumerate(erc_list):\n",
    "    \n",
    "    xtree = et.parse(path)\n",
    "    xroot = xtree.getroot()\n",
    "    xml_cols = [\"name\", \"label\", \"description\", \"field_type\",\"mandatory\",\"multiplicity\", \"ERC\"]\n",
    "    xml_rows = []\n",
    "\n",
    "    for sets in xroot.iter('FIELD'):\n",
    "        print(sets.find('NAME').text)\n",
    "        r_name = sets.find('NAME').text if sets is not None else None   \n",
    "        r_label = sets.find('LABEL').text if sets is not None else None\n",
    "        r_description = sets.find('DESCRIPTION').text if sets.find('DESCRIPTION') is not None else None      \n",
    "        r_field_type = sets.find('FIELD_TYPE').text if sets is not None else None      \n",
    "        r_mandatory = sets.find('MANDATORY').text if sets is not None else None      \n",
    "        r_multiplicity = sets.find('MULTIPLICITY').text if sets is not None else None   \n",
    "        xml_rows.append([r_name, r_label, r_description, r_field_type, r_mandatory, r_multiplicity,erc_list_name[index] ])    \n",
    "    xml_table= pd.DataFrame(xml_rows, columns= xml_cols)\n",
    "    output_list.append(xml_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_table_37 = xml_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list[0][[\"name\",\"mandatory\"]][output_list[0][[\"name\",\"mandatory\"]][\"mandatory\"]==\"mandatory\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " output_list[2][[\"name\",\"mandatory\"]][output_list[2][[\"name\",\"mandatory\"]][\"mandatory\"]==\"mandatory\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_output2 = output_list[2].set_index('name').join(output_list[0].set_index('name'), lsuffix='_37', rsuffix='_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_output = pd.concat([output_list[0].set_index('name'),output_list[2].set_index('name')])\n",
    "mandatory = all_output[[\"name\",\"mandatory_20\", \"mandatory_37\"]][(all_output[\"mandatory_20\"]==\"mandatory\") |(all_output[\"mandatory_37\"]==\"mandatory\") ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mandatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate =all_output[[\"mandatory_20\", \"mandatory_37\"]][(pd.notna(all_output[\"mandatory_20\"])) &(pd.notna(all_output[\"mandatory_37\"])) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mandatory_20    48\n",
       "mandatory_37    48\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>mandatory_20</th>\n",
       "      <th>mandatory_37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>project name</td>\n",
       "      <td>mandatory</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sequencing method</td>\n",
       "      <td>mandatory</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>collection date</td>\n",
       "      <td>mandatory</td>\n",
       "      <td>mandatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>geographic location (country and/or sea)</td>\n",
       "      <td>mandatory</td>\n",
       "      <td>mandatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>geographic location (latitude)</td>\n",
       "      <td>mandatory</td>\n",
       "      <td>mandatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>geographic location (longitude)</td>\n",
       "      <td>mandatory</td>\n",
       "      <td>mandatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>broad-scale environmental context</td>\n",
       "      <td>mandatory</td>\n",
       "      <td>optional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>local environmental context</td>\n",
       "      <td>mandatory</td>\n",
       "      <td>optional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>environmental medium</td>\n",
       "      <td>mandatory</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>isolation and growth condition</td>\n",
       "      <td>optional</td>\n",
       "      <td>mandatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>plant structure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mandatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>plant developmental stage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mandatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>plant growth medium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mandatory</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         name mandatory_20 mandatory_37\n",
       "0                                project name    mandatory          NaN\n",
       "22                          sequencing method    mandatory          NaN\n",
       "29                            collection date    mandatory    mandatory\n",
       "31   geographic location (country and/or sea)    mandatory    mandatory\n",
       "32             geographic location (latitude)    mandatory    mandatory\n",
       "33            geographic location (longitude)    mandatory    mandatory\n",
       "36          broad-scale environmental context    mandatory     optional\n",
       "37                local environmental context    mandatory     optional\n",
       "38                       environmental medium    mandatory          NaN\n",
       "42             isolation and growth condition     optional    mandatory\n",
       "106                           plant structure          NaN    mandatory\n",
       "107                 plant developmental stage          NaN    mandatory\n",
       "141                       plant growth medium          NaN    mandatory"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_output = pd.merge(output_list[0],output_list[2], on='name',how='outer', suffixes=('_20', '_37'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_37</th>\n",
       "      <th>description_37</th>\n",
       "      <th>field_type_37</th>\n",
       "      <th>mandatory_37</th>\n",
       "      <th>multiplicity_37</th>\n",
       "      <th>ERC_37</th>\n",
       "      <th>label_20</th>\n",
       "      <th>description_20</th>\n",
       "      <th>field_type_20</th>\n",
       "      <th>mandatory_20</th>\n",
       "      <th>multiplicity_20</th>\n",
       "      <th>ERC_20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ploidy</th>\n",
       "      <td>ploidy</td>\n",
       "      <td>The ploidy level of the genome (e.g. allopolyp...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>recommended</td>\n",
       "      <td>single</td>\n",
       "      <td>ERC000037.xml</td>\n",
       "      <td>ploidy</td>\n",
       "      <td>The ploidy level of the genome (e.g. allopolyp...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000020.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number of replicons</th>\n",
       "      <td>number of replicons</td>\n",
       "      <td>Reports the number of replicons in a nuclear g...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>recommended</td>\n",
       "      <td>single</td>\n",
       "      <td>ERC000037.xml</td>\n",
       "      <td>number of replicons</td>\n",
       "      <td>Reports the number of replicons in a nuclear g...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000020.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extrachromosomal elements</th>\n",
       "      <td>extrachromosomal elements</td>\n",
       "      <td>Do plasmids exist of significant phenotypic co...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000037.xml</td>\n",
       "      <td>extrachromosomal elements</td>\n",
       "      <td>Do plasmids exist of significant phenotypic co...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000020.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estimated size</th>\n",
       "      <td>estimated size</td>\n",
       "      <td>The estimated size of the genome (in bp) prior...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>recommended</td>\n",
       "      <td>single</td>\n",
       "      <td>ERC000037.xml</td>\n",
       "      <td>estimated size</td>\n",
       "      <td>The estimated size of the genome (in bp) prior...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000020.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample volume or weight for DNA extraction</th>\n",
       "      <td>sample volume or weight for DNA extraction</td>\n",
       "      <td>Volume (ml) or mass (g) of total collected sam...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>single</td>\n",
       "      <td>ERC000037.xml</td>\n",
       "      <td>sample volume or weight for DNA extraction</td>\n",
       "      <td>Volume (ml) or mass (g) of total collected sam...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000020.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>light regimen</th>\n",
       "      <td>light regimen</td>\n",
       "      <td>information about treatment involving an expos...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>recommended</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000037.xml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biotic regimen</th>\n",
       "      <td>biotic regimen</td>\n",
       "      <td>information about treatment involving use of b...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000037.xml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mechanical damage</th>\n",
       "      <td>mechanical damage</td>\n",
       "      <td>information about any mechanical damage exerte...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000037.xml</td>\n",
       "      <td>mechanical damage</td>\n",
       "      <td>information about any mechanical damage exerte...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000020.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chemical administration</th>\n",
       "      <td>chemical administration</td>\n",
       "      <td>list of chemical compounds administered to the...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000037.xml</td>\n",
       "      <td>chemical administration</td>\n",
       "      <td>list of chemical compounds administered to the...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000020.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perturbation</th>\n",
       "      <td>perturbation</td>\n",
       "      <td>type of perturbation, e.g. chemical administra...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000037.xml</td>\n",
       "      <td>perturbation</td>\n",
       "      <td>type of perturbation, e.g. chemical administra...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>optional</td>\n",
       "      <td>multiple</td>\n",
       "      <td>ERC000020.xml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              label_37  \\\n",
       "name                                                                                     \n",
       "ploidy                                                                          ploidy   \n",
       "number of replicons                                                number of replicons   \n",
       "extrachromosomal elements                                    extrachromosomal elements   \n",
       "estimated size                                                          estimated size   \n",
       "sample volume or weight for DNA extraction  sample volume or weight for DNA extraction   \n",
       "...                                                                                ...   \n",
       "light regimen                                                            light regimen   \n",
       "biotic regimen                                                          biotic regimen   \n",
       "mechanical damage                                                    mechanical damage   \n",
       "chemical administration                                        chemical administration   \n",
       "perturbation                                                              perturbation   \n",
       "\n",
       "                                                                               description_37  \\\n",
       "name                                                                                            \n",
       "ploidy                                      The ploidy level of the genome (e.g. allopolyp...   \n",
       "number of replicons                         Reports the number of replicons in a nuclear g...   \n",
       "extrachromosomal elements                   Do plasmids exist of significant phenotypic co...   \n",
       "estimated size                              The estimated size of the genome (in bp) prior...   \n",
       "sample volume or weight for DNA extraction  Volume (ml) or mass (g) of total collected sam...   \n",
       "...                                                                                       ...   \n",
       "light regimen                               information about treatment involving an expos...   \n",
       "biotic regimen                              information about treatment involving use of b...   \n",
       "mechanical damage                           information about any mechanical damage exerte...   \n",
       "chemical administration                     list of chemical compounds administered to the...   \n",
       "perturbation                                type of perturbation, e.g. chemical administra...   \n",
       "\n",
       "                                                               field_type_37  \\\n",
       "name                                                                           \n",
       "ploidy                                      \\n                                 \n",
       "number of replicons                         \\n                                 \n",
       "extrachromosomal elements                   \\n                                 \n",
       "estimated size                              \\n                                 \n",
       "sample volume or weight for DNA extraction  \\n                                 \n",
       "...                                                                      ...   \n",
       "light regimen                               \\n                                 \n",
       "biotic regimen                              \\n                                 \n",
       "mechanical damage                           \\n                                 \n",
       "chemical administration                     \\n                                 \n",
       "perturbation                                \\n                                 \n",
       "\n",
       "                                           mandatory_37 multiplicity_37  \\\n",
       "name                                                                      \n",
       "ploidy                                      recommended          single   \n",
       "number of replicons                         recommended          single   \n",
       "extrachromosomal elements                      optional        multiple   \n",
       "estimated size                              recommended          single   \n",
       "sample volume or weight for DNA extraction     optional          single   \n",
       "...                                                 ...             ...   \n",
       "light regimen                               recommended        multiple   \n",
       "biotic regimen                                 optional        multiple   \n",
       "mechanical damage                              optional        multiple   \n",
       "chemical administration                        optional        multiple   \n",
       "perturbation                                   optional        multiple   \n",
       "\n",
       "                                                   ERC_37  \\\n",
       "name                                                        \n",
       "ploidy                                      ERC000037.xml   \n",
       "number of replicons                         ERC000037.xml   \n",
       "extrachromosomal elements                   ERC000037.xml   \n",
       "estimated size                              ERC000037.xml   \n",
       "sample volume or weight for DNA extraction  ERC000037.xml   \n",
       "...                                                   ...   \n",
       "light regimen                               ERC000037.xml   \n",
       "biotic regimen                              ERC000037.xml   \n",
       "mechanical damage                           ERC000037.xml   \n",
       "chemical administration                     ERC000037.xml   \n",
       "perturbation                                ERC000037.xml   \n",
       "\n",
       "                                                                              label_20  \\\n",
       "name                                                                                     \n",
       "ploidy                                                                          ploidy   \n",
       "number of replicons                                                number of replicons   \n",
       "extrachromosomal elements                                    extrachromosomal elements   \n",
       "estimated size                                                          estimated size   \n",
       "sample volume or weight for DNA extraction  sample volume or weight for DNA extraction   \n",
       "...                                                                                ...   \n",
       "light regimen                                                                      NaN   \n",
       "biotic regimen                                                                     NaN   \n",
       "mechanical damage                                                    mechanical damage   \n",
       "chemical administration                                        chemical administration   \n",
       "perturbation                                                              perturbation   \n",
       "\n",
       "                                                                               description_20  \\\n",
       "name                                                                                            \n",
       "ploidy                                      The ploidy level of the genome (e.g. allopolyp...   \n",
       "number of replicons                         Reports the number of replicons in a nuclear g...   \n",
       "extrachromosomal elements                   Do plasmids exist of significant phenotypic co...   \n",
       "estimated size                              The estimated size of the genome (in bp) prior...   \n",
       "sample volume or weight for DNA extraction  Volume (ml) or mass (g) of total collected sam...   \n",
       "...                                                                                       ...   \n",
       "light regimen                                                                             NaN   \n",
       "biotic regimen                                                                            NaN   \n",
       "mechanical damage                           information about any mechanical damage exerte...   \n",
       "chemical administration                     list of chemical compounds administered to the...   \n",
       "perturbation                                type of perturbation, e.g. chemical administra...   \n",
       "\n",
       "                                                               field_type_20  \\\n",
       "name                                                                           \n",
       "ploidy                                      \\n                                 \n",
       "number of replicons                         \\n                                 \n",
       "extrachromosomal elements                   \\n                                 \n",
       "estimated size                              \\n                                 \n",
       "sample volume or weight for DNA extraction  \\n                                 \n",
       "...                                                                      ...   \n",
       "light regimen                                                            NaN   \n",
       "biotic regimen                                                           NaN   \n",
       "mechanical damage                           \\n                                 \n",
       "chemical administration                     \\n                                 \n",
       "perturbation                                \\n                                 \n",
       "\n",
       "                                           mandatory_20 multiplicity_20  \\\n",
       "name                                                                      \n",
       "ploidy                                         optional        multiple   \n",
       "number of replicons                            optional        multiple   \n",
       "extrachromosomal elements                      optional        multiple   \n",
       "estimated size                                 optional        multiple   \n",
       "sample volume or weight for DNA extraction     optional        multiple   \n",
       "...                                                 ...             ...   \n",
       "light regimen                                       NaN             NaN   \n",
       "biotic regimen                                      NaN             NaN   \n",
       "mechanical damage                              optional        multiple   \n",
       "chemical administration                        optional        multiple   \n",
       "perturbation                                   optional        multiple   \n",
       "\n",
       "                                                   ERC_20  \n",
       "name                                                       \n",
       "ploidy                                      ERC000020.xml  \n",
       "number of replicons                         ERC000020.xml  \n",
       "extrachromosomal elements                   ERC000020.xml  \n",
       "estimated size                              ERC000020.xml  \n",
       "sample volume or weight for DNA extraction  ERC000020.xml  \n",
       "...                                                   ...  \n",
       "light regimen                                         NaN  \n",
       "biotic regimen                                        NaN  \n",
       "mechanical damage                           ERC000020.xml  \n",
       "chemical administration                     ERC000020.xml  \n",
       "perturbation                                ERC000020.xml  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Started Reading JSON file\")\n",
    "with open(\"inv.json\", \"r\") as read_file:\n",
    "    print(\"Converting JSON encoded data into Python dictionary\")\n",
    "    arc_json = json.load(read_file)\n",
    "\n",
    "    print(\"Decoded JSON Data From File\")\n",
    "    for key, value in arc_json.items():\n",
    "        print(key, \":\", value)\n",
    "    print(\"Done reading json file\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(np.arange(0,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new function (rewritten)\n",
    "# print(\"Started Reading JSON file\")\n",
    "\n",
    "\n",
    "def append_table_protocol(element, json_rows):\n",
    "\n",
    "    for parameter in element:\n",
    "\n",
    "        p=parameter.get('parameterName') if parameter.get('parameterName') is not None else None\n",
    "#         print(p)\n",
    "        term_name = p.get('annotationValue') if p.get('annotationValue') is not None else None\n",
    "        print('name is: '+ term_name )\n",
    "        term_source = p.get('termSource') if p.get('termSource')  is not None else None\n",
    "        print( term_source)\n",
    "        term_accession = p.get('termAccession') if p.get('termAccession')  is not None else None\n",
    "        print( term_accession)                          \n",
    "        index_value= p.get('comments')[0].get(\"value\")\n",
    "        json_rows.append( [file_id,\n",
    "                           arc_id, \n",
    "                           subsection_id,\n",
    "                           input_id, \n",
    "                           input_name,\n",
    "\n",
    "                           output_id, \n",
    "                           output_name,\n",
    "                           derived_from,\n",
    "                           term_type,\n",
    "                           term_name, \n",
    "                           term_source, \n",
    "                           term_accession, \n",
    "                           index_value, \n",
    "                           value])\n",
    "#         print('index value is: '+ term_value)\n",
    "        \n",
    "\n",
    "\n",
    "def append_table_assays(element, json_rows, option= 1):\n",
    "    \n",
    "    for parameter in element:\n",
    "\n",
    "        c= parameter.get(\"category\")\n",
    "        p=c.get('parameterName') if c.get('parameterName') is not None else None\n",
    "#         print(p)\n",
    "        value = parameter.get('value') if parameter.get('value') is not None else None\n",
    "        term_name = p.get('annotationValue') if p.get('annotationValue') is not None else None\n",
    "#         print('name is: '+ term_name )\n",
    "        term_source = p.get('termSource') if (p.get('termSource') ) is not None else None\n",
    "#         print( term_source)\n",
    "        term_accession = p.get('termAccession') if (p.get('termAccession') ) is not None else None\n",
    "#         print( term_accession)\n",
    "        term_type = \"parameter\"\n",
    "        index_value= p.get('comments')[0].get(\"value\")\n",
    "        \n",
    "        json_rows.append( [file_id, \n",
    "                           arc_id, \n",
    "                           subsection_id,\n",
    "                           input_id, \n",
    "                           input_name,\n",
    "\n",
    "                           output_id, \n",
    "                           output_name,\n",
    "                           derived_from,\n",
    "                           term_type,\n",
    "                           term_name, \n",
    "                           term_source, \n",
    "                           term_accession, \n",
    "                           index_value, \n",
    "                           value])\n",
    "#         print('index value is: '+ term_value)\n",
    "        \n",
    "def append_c_input(element, json_rows):\n",
    "    \n",
    "    for parameter in element:\n",
    "\n",
    "        b = parameter.get(\"category\")\n",
    "        factor = b.get(\"characteristicType\") if b.get(\"characteristicType\") is not None else None\n",
    "#         print(p)\n",
    "        value = parameter.get('value') if parameter.get('value') is not None else None\n",
    "        term_name = factor.get('annotationValue') if factor.get('annotationValue') is not None else None\n",
    "#         print('name is: '+ term_name )\n",
    "        term_source = factor.get('termSource') if (factor.get('termSource') ) is not None else None\n",
    "#         print( term_source)\n",
    "        term_accession = factor.get('termAccession') if (factor.get('termAccession') ) is not None else None\n",
    "#         print( term_accession)\n",
    "        term_type = \"parameter\"\n",
    "        index_value= factor.get('comments')[0].get(\"value\")\n",
    "        json_rows.append( [file_id, \n",
    "                           arc_id, \n",
    "                           subsection_id,\n",
    "                           input_id, \n",
    "                           input_name,\n",
    "\n",
    "                           output_id, \n",
    "                           output_name,\n",
    "                           derived_from,\n",
    "                           term_type,\n",
    "                           term_name, \n",
    "                           term_source, \n",
    "                           term_accession, \n",
    "                           index_value, \n",
    "                           value])\n",
    "#         print('index value is: '+ term_value)\n",
    "\n",
    "def append_input(element, json_rows):\n",
    "    \n",
    "    for parameter in element:\n",
    "\n",
    "        b = parameter.get(\"category\")\n",
    "        factor = b.get(\"factorType\") if b.get(\"factorType\") is not None else None\n",
    "#         print(p)\n",
    "\n",
    "        value = parameter.get('value') if parameter.get('value') is not None else None\n",
    "        term_name = factor.get('annotationValue') if factor.get('annotationValue') is not None else None\n",
    "#         print('name is: '+ term_name )\n",
    "        term_source = factor.get('termSource') if (factor.get('termSource') ) is not None else None\n",
    "#         print( term_source)\n",
    "        term_accession = factor.get('termAccession') if (factor.get('termAccession') ) is not None else None\n",
    "#         print( term_accession)\n",
    "        term_type = \"factor\"\n",
    "        index_value= factor.get('comments')[0].get(\"value\")\n",
    "        json_rows.append( [file_id, \n",
    "                           arc_id, \n",
    "                           subsection_id,\n",
    "                           input_id, \n",
    "                           input_name,\n",
    "\n",
    "                           output_id, \n",
    "                           output_name,\n",
    "                           derived_from,\n",
    "                           term_type,\n",
    "                           term_name, \n",
    "                           term_source, \n",
    "                           term_accession, \n",
    "                           index_value, \n",
    "                           value])\n",
    "#         print('index value is: '+ term_value)\n",
    "\n",
    "def append_output(element, json_rows):\n",
    "    \n",
    "    for parameter in element:\n",
    "        \n",
    "        b = parameter.get(\"category\")\n",
    "        factor = b.get(\"factorType\") if b.get(\"factorType\") is not None else None\n",
    "#         print(p)\n",
    "\n",
    "        value = parameter.get('value') if parameter.get('value') is not None else None\n",
    "        term_name = factor.get('annotationValue') if factor.get('annotationValue') is not None else None\n",
    "#         print('name is: '+ term_name )\n",
    "        term_source = factor.get('termSource') if (factor.get('termSource') ) is not None else None\n",
    "#         print( term_source)\n",
    "        term_accession = factor.get('termAccession') if (factor.get('termAccession') ) is not None else None\n",
    "#         print( term_accession)\n",
    "        term_type = 'factor'\n",
    "        index_value= factor.get('comments')[0].get(\"value\")\n",
    "        json_rows.append( [file_id, \n",
    "                           arc_id, \n",
    "                           subsection_id,\n",
    "                           input_id, \n",
    "                           input_name,\n",
    "\n",
    "                           output_id, \n",
    "                           output_name,\n",
    "                           derived_from,\n",
    "                           term_type,\n",
    "                           term_name, \n",
    "                           term_source, \n",
    "                           term_accession, \n",
    "                           index_value, \n",
    "                           value])\n",
    "#         print('index value is: '+ term_value)\n",
    "#         print('index value is: '+ term_value)\n",
    "# todo factorValues, derived from\n",
    "\n",
    "def init_none():\n",
    "    global input_id \n",
    "    global input_name \n",
    "    global output_id\n",
    "    global output_name \n",
    "    global derived_from \n",
    "    global value \n",
    "    global index_value\n",
    "    global term_type\n",
    "    global term_name\n",
    "    global term_source \n",
    "    global term_accession \n",
    "    input_id = None\n",
    "    input_name = None\n",
    "    output_id = None\n",
    "    output_name = None\n",
    "    derived_from = None\n",
    "    value = None\n",
    "    index_value = None\n",
    "    term_type = None\n",
    "    term_name = None\n",
    "    term_source = None\n",
    "    term_accession = None\n",
    "    \n",
    "def write_smaple_xml(xml_input):\n",
    "    input_ = xml_input[xml_input[\"subsection_id\"].str.match(r'1SPL01_plants_')==True ]\n",
    "    sample= input_\n",
    "    input_list = sample[sample[\"input_name\"].notna()]\n",
    "    output_list = sample[sample[\"output_name\"].notna()]\n",
    "\n",
    "    a = et.Element('SAMPLE_SET')\n",
    "    for i,input_name in enumerate(input_list[\"input_name\"].unique()):\n",
    "        one_sample = sample[sample['input_name'] == input_name]\n",
    "        for i, tags in enumerate(one_sample):\n",
    "            b = et.SubElement(a, 'SAMPLE')\n",
    "\n",
    "            b.attrib = {'alias': input_name , 'center_name':''}\n",
    "            c = et.SubElement(b, 'TITLE')\n",
    "            c.text = one_sample[one_sample['term_name']== 'Organism']['value'].to_string(header=False, index=False)\n",
    "\n",
    "            d = et.SubElement(b, 'SAMPLE_NAME')\n",
    "            d.text = input_name\n",
    "\n",
    "            e = et.SubElement(d, 'TAXON_ID')\n",
    "            e.text = 'id'\n",
    "            f = et.SubElement(d, 'SCIENTIFIC_NAME')\n",
    "            f.text = c.text = one_sample[one_sample['term_name']== 'Organism']['value'].to_string(header=False, index=False)\n",
    "\n",
    "            g = et.SubElement(d, 'COMMON_NAME')\n",
    "            g.text = 'id'\n",
    "\n",
    "            h = et.SubElement(b, 'SAMPLE_ATTRIBUTES')\n",
    "            for index, row in one_sample.iterrows():\n",
    "                i = et.SubElement(h,'SAMPLE_ATTRIBUTE' )\n",
    "                j = et.SubElement(i, 'TAG')\n",
    "                j.text = str(row['term_name'])\n",
    "\n",
    "                k = et.SubElement(i, 'VALUE')\n",
    "                k.text = str(row['value']) \n",
    "\n",
    "\n",
    "    tree = et.ElementTree(a)\n",
    "    et.indent(tree, space=\" \\n\", level=0)\n",
    "    et.dump(a)\n",
    "    tree.write(\"SAMPLE.xml\", encoding=\"utf-8\")\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json():\n",
    "\n",
    "subsection_name = [\"studies\", \"assays\", \"factors\"]\n",
    "\n",
    "\n",
    "protocols =arc_json.get(section)[0].get('protocols')\n",
    "for i, process in enumerate(protocols):\n",
    "    if i > 3:\n",
    "        break\n",
    "    \n",
    "    init_none()\n",
    "    subsection_id = process.get(\"name\")\n",
    "    print(subsection_id)\n",
    "#     subsection = process.get('parameters')\n",
    "#     print(subsection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# new function\n",
    "\n",
    "def convert_json(arc_json_file, mapping_file):\n",
    "    with open(arc_json_file, \"r\") as read_file:\n",
    "#     print(\"Converting JSON encoded data into Python dictionary\")\n",
    "        arc_json = json.load(read_file)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    global file_id\n",
    "    global arc_id\n",
    "    global subsection_id\n",
    "    global input_id \n",
    "    global input_name \n",
    "    global output_id\n",
    "    global output_name \n",
    "    global derived_from \n",
    "    global value \n",
    "    global index_value\n",
    "    global term_type\n",
    "    global term_name\n",
    "    global term_source \n",
    "    global term_accessio\n",
    "    json_table= []\n",
    "    json_cols = [\"file_id\", \n",
    "                 \"arc_id\" , \n",
    "                 \"subsection_id\", \n",
    "                 \"input_id\", \n",
    "                 \"input_name\", \n",
    "\n",
    "                 \"output_id\", \n",
    "                 \"output_name\",\n",
    "                 \"derived_from\",\n",
    "                 \"term_type\",\n",
    "                 \"term_name\", \n",
    "                 \"term_source\", \n",
    "                 \"term_accession\", \n",
    "                 \"index_value\", \n",
    "                 \"value\", ]\n",
    "    json_rows = []\n",
    "    file_id = arc_json.get(\"identifier\")\n",
    "    section = \"studies\"\n",
    "    studies = arc_json.get(\"studies\")\n",
    "\n",
    "    arc_id = studies[0].get(\"identifier\")\n",
    "    processSequences = arc_json.get(\"studies\")[0].get('assays')[0].get(\"processSequence\")\n",
    "\n",
    "    for process_seq in processSequences:\n",
    "\n",
    "        subsection_id = process_seq.get(\"name\")\n",
    "        print(subsection_id)\n",
    "\n",
    "        parameter_values = process_seq.get(\"parameterValues\")\n",
    "        append_table_assays(parameter_values, json_rows)\n",
    "        init_none() \n",
    "        input_section = process_seq.get(\"inputs\")\n",
    "        if input_section != None:\n",
    "    #     print(input_section)\n",
    "            for i,input_ in enumerate(input_section):\n",
    "                input_name = input_.get(\"name\")\n",
    "                input_id = i\n",
    "\n",
    "                derived_from = input_.get(\"derivesFrom\")[0].get(\"name\") if input_.get(\"derivesFrom\") is not None else None\n",
    "                print(input_name + \" derivesFrom is \", derived_from)\n",
    "                characteristics = input_.get(\"characteristics\") \n",
    "                if characteristics != None:\n",
    "                    append_c_input(characteristics,json_rows)\n",
    "                factorvalues = input_.get(\"factorValues\") \n",
    "                if factorvalues != None:\n",
    "                        append_input(factorvalues,json_rows)\n",
    "\n",
    "\n",
    "\n",
    "        init_none()    \n",
    "        output_section = process_seq.get(\"outputs\")\n",
    "\n",
    "    #     print(output_section)\n",
    "        for i, output_ in enumerate(output_section):\n",
    "            output_name = output_.get(\"name\")\n",
    "            output_id = i\n",
    "            derived_from = output_.get(\"derivesFrom\")[0].get(\"name\") if output_.get(\"derivesFrom\") is not None else None\n",
    "            print(output_name + \" and derived from is \", derived_from)\n",
    "\n",
    "            term_type = output_.get('type') if output_.get('type') is not None else None\n",
    "\n",
    "            factorvalues = output_.get(\"factorValues\") \n",
    "            if factorvalues != None:\n",
    "                append_output(factorvalues,json_rows)\n",
    "            else:\n",
    "                json_rows.append( [file_id, \n",
    "                               arc_id, \n",
    "                               subsection_id,\n",
    "                               input_id, \n",
    "                               input_name,\n",
    "\n",
    "                               output_id, \n",
    "                               output_name,\n",
    "                               derived_from,\n",
    "                                   term_type,\n",
    "                               term_name, \n",
    "                               term_source, \n",
    "                               term_accession, \n",
    "                               index_value, \n",
    "                               value])\n",
    "\n",
    "\n",
    "\n",
    "    json_table = pd.DataFrame(json_rows, columns= json_cols)\n",
    "    mapping = pd.read_excel(mapping_file)\n",
    "    term_id = mapping.iloc[:,2]\n",
    "    mapping.iloc[:,3] = term_id.map( lambda x: \"http://purl.obolibrary.org/obo/{}\".format( str(x).replace(\":\", \"_\") )  )\n",
    "\n",
    "    \n",
    "    json_table[\"ena_id\"] = json_table[\"term_name\"]\n",
    "    a = json_table.loc[:, \"ena_id\"]\n",
    "    # a = json_table.loc[:, \"term_accession\"]\n",
    "    term_mapping = mapping.iloc[:,3]\n",
    "    for i, term in enumerate(term_mapping):\n",
    "         cond = json_table[\"term_accession\"] == term\n",
    "    #     print(term)\n",
    "    #     print(filter_)\n",
    "         a.mask(cond , mapping.loc[:, \"Field Name\"][i], inplace= True)\n",
    "    json_table.to_csv('json_table_new.csv')\n",
    "    \n",
    "    \n",
    "    a = et.Element('PROJECT_SET')\n",
    "    for i,project in enumerate(arc_json.get(\"studies\")):\n",
    "        b = et.SubElement(a, 'PROJECT')\n",
    "\n",
    "        b.attrib = {'alias': project.get('identifier')}\n",
    "        c = et.SubElement(b, 'TITLE')\n",
    "        c.text = project.get('title')\n",
    "        d = et.SubElement(b, 'DESCRIPTION')\n",
    "        d.text = str(arc_json.get(\"publications\"))\n",
    "        f = et.SubElement(b, \"SUBMISSION_PROJECT\")\n",
    "        g = et.SubElement(f, \"SEQUENCING_PROJECT\")\n",
    "    tree = et.ElementTree(a)\n",
    "    et.indent(tree, space=\" \\n\", level=0)\n",
    "\n",
    "    tree.write(\"study.xml\", encoding=\"utf-8\")\n",
    "\n",
    "    # sample xml\n",
    "    xml_input = pd.read_csv(\"json_table_new.csv\")\n",
    "    write_smaple_xml(xml_input)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1SPL01_plants_0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'input_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m arc_json_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minv_old.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m mapping_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmapping_ERC000037.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mconvert_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43marc_json_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 56\u001b[0m, in \u001b[0;36mconvert_json\u001b[0;34m(arc_json_file, mapping_file)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(subsection_id)\n\u001b[1;32m     55\u001b[0m parameter_values \u001b[38;5;241m=\u001b[39m process_seq\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameterValues\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m \u001b[43mappend_table_assays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameter_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_rows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m init_none() \n\u001b[1;32m     58\u001b[0m input_section \u001b[38;5;241m=\u001b[39m process_seq\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 57\u001b[0m, in \u001b[0;36mappend_table_assays\u001b[0;34m(element, json_rows, option)\u001b[0m\n\u001b[1;32m     51\u001b[0m term_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m index_value\u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomments\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m json_rows\u001b[38;5;241m.\u001b[39mappend( [file_id, \n\u001b[1;32m     55\u001b[0m                    arc_id, \n\u001b[1;32m     56\u001b[0m                    subsection_id,\n\u001b[0;32m---> 57\u001b[0m                    \u001b[43minput_id\u001b[49m, \n\u001b[1;32m     58\u001b[0m                    input_name,\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m                    output_id, \n\u001b[1;32m     61\u001b[0m                    output_name,\n\u001b[1;32m     62\u001b[0m                    derived_from,\n\u001b[1;32m     63\u001b[0m                    term_type,\n\u001b[1;32m     64\u001b[0m                    term_name, \n\u001b[1;32m     65\u001b[0m                    term_source, \n\u001b[1;32m     66\u001b[0m                    term_accession, \n\u001b[1;32m     67\u001b[0m                    index_value, \n\u001b[1;32m     68\u001b[0m                    value])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_id' is not defined"
     ]
    }
   ],
   "source": [
    "arc_json_file = 'inv_old.json'\n",
    "mapping_file = 'mapping_ERC000037.xlsx'\n",
    "convert_json(arc_json_file, mapping_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "json_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_tabble.to_csv(\"save.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pd.read_excel(\"mapping_ERC000037.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_id = mapping.iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mapping.iloc[:,3] = term_id.map( lambda x: \"http://purl.obolibrary.org/obo/{}\".format( str(x).replace(\":\", \"_\") )  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping.to_csv(\"mapping_ERC000037_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ x ==  for x in mapping.iloc[:,3] ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rename some terms based on the ENA template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_table[\"ena_id\"] = json_table[\"term_name\"]\n",
    "a = json_table.loc[:, \"term_accession\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# json_table= []\n",
    "# json_cols = [\"file_id\", \n",
    "#              \"study_id\" , \n",
    "#              \"subsection_id\", \n",
    "#              \"input_id\", \n",
    "#              \"input_name\", \n",
    "\n",
    "#              \"output_id\", \n",
    "#              \"output_name\",\n",
    "#              \"derived_from\",\n",
    "#              \"term_name\", \n",
    "#              \"term_source\", \n",
    "#              \"term_accession\", \n",
    "#              \"index_value\", \n",
    "#              \"value\", ]\n",
    "# json_rows = []\n",
    "# file_id = arc_json.get(\"identifier\")\n",
    "# section = \"studies\"\n",
    "# study_id = arc_json.get(\"studies\")[0].get(\"identifier\")\n",
    "\n",
    "# def append_table_protocol(element):\n",
    "\n",
    "#     for parameter in element:\n",
    "\n",
    "#         p=parameter.get('parameterName') if parameter.get('parameterName') is not None else None\n",
    "# #         print(p)\n",
    "#         term_name = p.get('annotationValue') if p.get('annotationValue') is not None else None\n",
    "#         print('name is: '+ term_name )\n",
    "#         term_source = p.get('termSource') if p.get('termSource')  is not None else None\n",
    "#         print( term_source)\n",
    "#         term_accession = p.get('termAccession') if p.get('termAccession')  is not None else None\n",
    "#         print( term_accession)\n",
    "#         index_value= p.get('comments')[0].get(\"value\")\n",
    "#         json_rows.append( [file_id, \n",
    "#                            study_id, \n",
    "#                            subsection_id,\n",
    "#                            input_id, \n",
    "#                            input_name,\n",
    "\n",
    "#                            output_id, \n",
    "#                            output_name,\n",
    "#                            derived_from,\n",
    "#                            term_name, \n",
    "#                            term_source, \n",
    "#                            term_accession, \n",
    "#                            index_value, \n",
    "#                            value])\n",
    "# #         print('index value is: '+ term_value)\n",
    "        \n",
    "\n",
    "\n",
    "# def append_table_assays(element, option= 1):\n",
    "    \n",
    "#     for parameter in element:\n",
    "\n",
    "#         c= parameter.get(\"category\")\n",
    "#         p=c.get('parameterName') if c.get('parameterName') is not None else None\n",
    "# #         print(p)\n",
    "#         value = c.get('value') if c.get('value') is not None else None\n",
    "#         term_name = p.get('annotationValue') if p.get('annotationValue') is not None else None\n",
    "# #         print('name is: '+ term_name )\n",
    "#         term_source = p.get('termSource') if (p.get('termSource') ) is not None else None\n",
    "# #         print( term_source)\n",
    "#         term_accession = p.get('termAccession') if (p.get('termAccession') ) is not None else None\n",
    "# #         print( term_accession)\n",
    "#         index_value= p.get('comments')[0].get(\"value\")\n",
    "\n",
    "#         json_rows.append( [file_id, \n",
    "#                            study_id, \n",
    "#                            subsection_id,\n",
    "#                            input_id, \n",
    "#                            input_name,\n",
    "\n",
    "#                            output_id, \n",
    "#                            output_name,\n",
    "#                            derived_from,\n",
    "#                            term_name, \n",
    "#                            term_source, \n",
    "#                            term_accession, \n",
    "#                            index_value, \n",
    "#                            value])\n",
    "# #         print('index value is: '+ term_value)\n",
    "        \n",
    "\n",
    "\n",
    "# def append_input(element):\n",
    "    \n",
    "#     for parameter in element:\n",
    "\n",
    "#         b = parameter.get(\"category\")\n",
    "#         p = b.get(\"characteristicType\") if b.get(\"characteristicType\") is not None else None\n",
    "# #         print(p)\n",
    "#         value = b.get('value') if b.get('value') is not None else None\n",
    "#         term_name = p.get('annotationValue') if p.get('annotationValue') is not None else None\n",
    "# #         print('name is: '+ term_name )\n",
    "#         term_source = p.get('termSource') if (p.get('termSource') ) is not None else None\n",
    "# #         print( term_source)\n",
    "#         term_accession = p.get('termAccession') if (p.get('termAccession') ) is not None else None\n",
    "# #         print( term_accession)\n",
    "#         index_value= p.get('comments')[0].get(\"value\")\n",
    "#         json_rows.append( [file_id, \n",
    "#                            study_id, \n",
    "#                            subsection_id,\n",
    "#                            input_id, \n",
    "#                            input_name,\n",
    "\n",
    "#                            output_id, \n",
    "#                            output_name,\n",
    "#                            derived_from,\n",
    "#                            term_name, \n",
    "#                            term_source, \n",
    "#                            term_accession, \n",
    "#                            index_value, \n",
    "#                            value])\n",
    "# #         print('index value is: '+ term_value)\n",
    "\n",
    "\n",
    "\n",
    "# def init_none():\n",
    "#     global input_id \n",
    "#     global input_name \n",
    "#     global output_id\n",
    "#     global output_name \n",
    "#     global derived_from \n",
    "#     global value \n",
    "#     global index_value \n",
    "#     global term_name\n",
    "#     global term_source \n",
    "#     global term_accession \n",
    "#     input_id = None\n",
    "#     input_name = None\n",
    "#     output_id = None\n",
    "#     output_name = None\n",
    "#     derived_from = None\n",
    "#     value = None\n",
    "#     index_value = None\n",
    "#     term_name = None\n",
    "#     term_source = None\n",
    "#     term_accession = None\n",
    "    \n",
    "# def append_output(element):   \n",
    "#     for parameter in element:\n",
    "#         b = parameter.get(\"category\")\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "# protocols =arc_json.get(section)[0].get('protocols')\n",
    "# for i, process in enumerate(protocols):\n",
    "#     if i > 3:\n",
    "#         break\n",
    "    \n",
    "#     init_none()\n",
    "#     subsection_id = process.get(\"name\")\n",
    "#     subsection = process.get('parameters')\n",
    "# #     print(subsection)\n",
    "#     append_table_protocol(subsection)\n",
    "\n",
    "# assays = arc_json.get(section)[0].get('assays')[0].get(\"processSequence\")\n",
    "\n",
    "# for process_seq in assays:\n",
    "#     init_none()\n",
    "    \n",
    "#     subsection_id = process_seq.get(\"name\")\n",
    "#     print(subsection_id)\n",
    "    \n",
    "#     parameter_values = process_seq.get(\"parameterValues\")\n",
    "#     append_table_assays(parameter_values)\n",
    "    \n",
    "#     input_section = process_seq.get(\"inputs\")\n",
    "#     if input_section != None:\n",
    "# #     print(input_section)\n",
    "#         for i,input_ in enumerate(input_section):\n",
    "#             input_name = input_.get(\"name\")\n",
    "#             input_id = i\n",
    "            \n",
    "#             print(input_name)\n",
    "#             derived_from = input_.get(\"derivedFrom\")[0].get(\"name\") if input_.get(\"derivedFrom\") is not None else None\n",
    "#             print(input_name + \" \", derived_from)\n",
    "#             characteristics = input_.get(\"characteristics\") \n",
    "#             if characteristics != None:\n",
    "#                 append_input(characteristics)\n",
    "#             else:\n",
    "#                 json_rows.append( [file_id, \n",
    "#                            study_id, \n",
    "#                            subsection_id,\n",
    "#                            input_id, \n",
    "#                            input_name,\n",
    "\n",
    "#                            output_id, \n",
    "#                            output_name,\n",
    "#                            derived_from,\n",
    "#                            term_name, \n",
    "#                            term_source, \n",
    "#                            term_accession, \n",
    "#                            index_value, \n",
    "#                            value])\n",
    "            \n",
    "#     init_none()    \n",
    "#     output_section = process_seq.get(\"outputs\")\n",
    "\n",
    "# #     print(output_section)\n",
    "#     for output_ in output_section:\n",
    "#         output_name = output_.get(\"name\")\n",
    "#         derived_from = output_.get(\"derivedFrom\")[0].get(\"name\") if output_.get(\"derivedFrom\") is not None else None\n",
    "#         print(output_name + \" \", derived_from)\n",
    "#         characteristics = output_.get(\"characteristics\") \n",
    "#         if characteristics != None:\n",
    "#             append_input(characteristics)\n",
    "#         else:\n",
    "#             json_rows.append( [file_id, \n",
    "#                            study_id, \n",
    "#                            subsection_id,\n",
    "#                            input_id, \n",
    "#                            input_name,\n",
    "\n",
    "#                            output_id, \n",
    "#                            output_name,\n",
    "#                            derived_from,\n",
    "#                            term_name, \n",
    "#                            term_source, \n",
    "#                            term_accession, \n",
    "#                            index_value, \n",
    "#                            value])\n",
    "\n",
    "\n",
    "        \n",
    "# json_table = pd.DataFrame(json_rows, columns= json_cols)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "json_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_table.to_csv(\"save.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assays = arc_json.get(section)[0].get('assays')[0].get(\"processSequence\")\n",
    "\n",
    "for process_seq in assays:\n",
    "    input_id = None\n",
    "    input_name = None\n",
    "    output_id = None\n",
    "    output_name = None\n",
    "\n",
    "    subsection_id = process_seq.get(\"name\")\n",
    "    print(subsection_id)\n",
    "\n",
    "    \n",
    "    input_section = process_seq.get(\"inputs\")\n",
    "#     print(input_section)\n",
    "\n",
    "    append_table(input_section)\n",
    "    output_section = process_seq.get(\"outputs\")\n",
    "    print(output_section)\n",
    "\n",
    "    append_table(output_section)\n",
    "\n",
    "        \n",
    "json_table = pd.DataFrame(json_rows, columns= json_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_json.get(section)[0].get('assays')[0].get(\"processSequence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_process_cols = [\"name\", \"source\", \"accession\", \"value\"]\n",
    "json_process_rows = []\n",
    "sample =arc_json.get('studies')[0].get('assays')[0].get('processSequence') #[0].get('parameterValues')\n",
    "sample\n",
    "# for subset in sample:\n",
    "#     category = subset.get(\"category\")\n",
    "#     p=category.get('parameterName')\n",
    "#     print(p)\n",
    "#     term_name = p.get('annotationValue')\n",
    "# #     print('name is: '+ term_name )\n",
    "#     term_source = p.get('termSource') if (p.get('termSource') ) is not None else None\n",
    "# #     print( term_source)\n",
    "#     term_accession = p.get('termAccession') if (p.get('termAccession') ) is not None else None\n",
    "# #     print( term_accession)\n",
    "#     term_value= p.get('comments')[0].get(\"value\")\n",
    "# #     print('index_value is: '+ term_value)\n",
    "#     value = subset.get('value') if subset.get('value') is not None else None\n",
    "#     print(\"{} is {}\".format( \"the value\" , value ) )\n",
    "#     json_process_rows.append( [term_name, term_source, term_accession, term_value])\n",
    "# json_process_table = pd.DataFrame(json_process_rows, columns= json_process_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_process_cols = [\"name\", \"source\", \"accession\", \"value\"]\n",
    "json_process_rows = []\n",
    "sample =arc_json.get('studies')[0].get('protocols')[0].get('parameters')\n",
    "for parameter in sample:\n",
    "    p=parameter.get('parameterName')\n",
    "    print(p)\n",
    "    term_name = p.get('annotationValue')\n",
    "    print('name is: '+ term_name )\n",
    "    term_source = p.get('termSource') if (p.get('termSource') ) is not None else None\n",
    "    print( term_source)\n",
    "    term_accession = p.get('termAccession') if (p.get('termAccession') ) is not None else None\n",
    "    print( term_accession)\n",
    "    term_value= p.get('comments')[0].get(\"value\")\n",
    "    print('index_value is: '+ term_value)\n",
    "    value = p.get('value') if p.get('value') is not None else None\n",
    "    print(\"{} is {}\".format( \"the value\" , value ) )\n",
    "    json_process_rows.append( [term_name, term_source, term_accession, term_value])\n",
    "json_process_table = pd.DataFrame(json_process_rows, columns= json_process_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_table = pd.read_excel(\"mapping.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "map_mandatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_mandatory =xml_table[xml_table[\"mandatory\"] == \"mandatory\" ]\n",
    "xml_table[xml_table[\"mandatory\"] == \"mandatory\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_table[xml_table[\"mandatory\"] == \"mandatory\" ].to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mandatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mandatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mandatory.replace(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "result = subprocess.run(['curl', \n",
    "                         '-u', \n",
    "                         'Webin-60802:EiZ6VR4H7FzaZDL', \n",
    "                         '-F' ,\n",
    "                         \"SUBMISSION=@./test/submission.xml\", \n",
    "                         '-F', \"PROJECT=@./test/study.xml\", \n",
    "                         \"https://wwwdev.ebi.ac.uk/ena/submit/drop-box/submit/\"], stdout=subprocess.PIPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = et.parse('./template-xmls/submission.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for child in root[0]:\n",
    "    print(child.tag, list(child)[1][0].attrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = et.parse('./template-xmls/study.xml')\n",
    "\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_json.get(\"studies\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [child for child in  root[0]]\n",
    "# root.findall(\"./PROJECT\")[0].set('alias', 'name')\n",
    "# root.findall(\"./PROJECT\")[0].get('alias')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "arc_json = pd.read_csv(\"inv.json\")\n",
    "a = et.Element('PROJECT_SET')\n",
    "for i,project in enumerate(arc_json.get(\"studies\")):\n",
    "    b = et.SubElement(a, 'PROJECT')\n",
    "\n",
    "    b.attrib = {'alias': project.get('identifier')}\n",
    "    c = et.SubElement(b, 'TITLE')\n",
    "    c.text = project.get('title')\n",
    "    d = et.SubElement(b, 'DESCRIPTION')\n",
    "    d.text = str(arc_json.get(\"publications\"))\n",
    "    f = et.SubElement(b, \"SUBMISSION_PROJECT\")\n",
    "    g = et.SubElement(f, \"SEQUENCING_PROJECT\")\n",
    "tree = et.ElementTree(a)\n",
    "et.indent(tree, space=\" \\n\", level=0)\n",
    "\n",
    "tree.write(\"study.xml\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_input = pd.read_csv(\"json_table_new.csv\")\n",
    "input_ = xml_input[xml_input[\"subsection_id\"].str.match(r'1SPL01_plants_')==True ]\n",
    "sample= input_\n",
    "input_list = sample[sample[\"input_name\"].notna()]\n",
    "output_list = sample[sample[\"output_name\"].notna()]\n",
    "\n",
    "input_list[\"input_name\"].unique()\n",
    "output_list[\"output_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,input_name in enumerate(input_list[\"input_name\"].unique()):\n",
    "    one_sample = sample[sample['input_name'] == input_name]\n",
    "    print(one_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list[\"input_name\"].unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample xml\n",
    "xml_input = pd.read_csv(\"json_table_new.csv\")\n",
    "def write_smaple_xml(xml_input):\n",
    "    input_ = xml_input[xml_input[\"subsection_id\"].str.match(r'1SPL01_plants_')==True ]\n",
    "    sample= input_\n",
    "    input_list = sample[sample[\"input_name\"].notna()]\n",
    "    output_list = sample[sample[\"output_name\"].notna()]\n",
    "    \n",
    "    a = et.Element('SAMPLE_SET')\n",
    "    for i,input_name in enumerate(input_list[\"input_name\"].unique()):\n",
    "        one_sample = sample[sample['input_name'] == input_name]\n",
    "        for i, tags in enumerate(one_sample):\n",
    "            b = et.SubElement(a, 'SAMPLE')\n",
    "\n",
    "            b.attrib = {'alias': input_name , 'center_name':''}\n",
    "            c = et.SubElement(b, 'TITLE')\n",
    "            c.text = one_sample[one_sample['term_name']== 'Organism']['value'].to_string(header=False, index=False)\n",
    "\n",
    "            d = et.SubElement(b, 'SAMPLE_NAME')\n",
    "            d.text = input_name\n",
    "\n",
    "            e = et.SubElement(d, 'TAXON_ID')\n",
    "            e.text = 'id'\n",
    "            f = et.SubElement(d, 'SCIENTIFIC_NAME')\n",
    "            f.text = c.text = one_sample[one_sample['term_name']== 'Organism']['value'].to_string(header=False, index=False)\n",
    "\n",
    "            g = et.SubElement(d, 'COMMON_NAME')\n",
    "            g.text = 'id'\n",
    "\n",
    "            h = et.SubElement(b, 'SAMPLE_ATTRIBUTES')\n",
    "            for index, row in one_sample.iterrows():\n",
    "                i = et.SubElement(h,'SAMPLE_ATTRIBUTE' )\n",
    "                j = et.SubElement(i, 'TAG')\n",
    "                j.text = row['term_name']\n",
    "\n",
    "                k = et.SubElement(i, 'VALUE')\n",
    "                k.text = str(row['value']) \n",
    "\n",
    "                \n",
    "    tree = et.ElementTree(a)\n",
    "    et.indent(tree, space=\" \\n\", level=0)\n",
    "    et.dump(a)\n",
    "    tree.write(\"SAMPLE.xml\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#     print(input_)\n",
    "    return input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_smaple_xml(xml_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[(sample[\"input_name\"].isna())& (sample[\"output_name\"].isna()) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_input = pd.read_csv(\"json_table_new.csv\")\n",
    "input_ = xml_input[xml_input[\"subsection_id\"].str.match(r'1SPL01_plants_')==True ]\n",
    "sample= input_\n",
    "input_list = sample[sample[\"input_name\"].notna()]\n",
    "output_list = sample[sample[\"output_name\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_sample = sample[sample['input_name'] == 'DB_097']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_sample[one_sample['term_name']== 'Organism']['value'].to_string(header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(one_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(one_sample['term_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project name\n",
      "experimental factor\n",
      "ploidy\n",
      "number of replicons\n",
      "extrachromosomal elements\n",
      "estimated size\n",
      "reference for biomaterial\n",
      "annotation source\n",
      "sample volume or weight for DNA extraction\n",
      "nucleic acid extraction\n",
      "nucleic acid amplification\n",
      "library size\n",
      "library reads sequenced\n",
      "library construction method\n",
      "library vector\n",
      "library screening strategy\n",
      "target gene\n",
      "target subfragment\n",
      "pcr primers\n",
      "multiplex identifiers\n",
      "adapters\n",
      "pcr conditions\n",
      "sequencing method\n",
      "sequence quality check\n",
      "chimera check software\n",
      "relevant electronic resources\n",
      "relevant standard operating procedures\n",
      "negative control type\n",
      "positive control type\n",
      "collection date\n",
      "altitude\n",
      "geographic location (country and/or sea)\n",
      "geographic location (latitude)\n",
      "geographic location (longitude)\n",
      "geographic location (region and locality)\n",
      "depth\n",
      "broad-scale environmental context\n",
      "local environmental context\n",
      "environmental medium\n",
      "elevation\n",
      "source material identifiers\n",
      "sample material processing\n",
      "isolation and growth condition\n",
      "propagation\n",
      "amount or size of sample collected\n",
      "host dry mass\n",
      "oxygenation status of sample\n",
      "plant product\n",
      "organism count\n",
      "sample storage duration\n",
      "sample storage temperature\n",
      "host wet mass\n",
      "sample storage location\n",
      "sample collection device\n",
      "sample collection method\n",
      "host disease status\n",
      "host common name\n",
      "host age\n",
      "host taxid\n",
      "host life stage\n",
      "host height\n",
      "host length\n",
      "plant body site\n",
      "host total mass\n",
      "host phenotype\n",
      "host subspecific genetic lineage\n",
      "climate environment\n",
      "gaseous environment\n",
      "seasonal environment\n",
      "temperature\n",
      "salinity\n",
      "host genotype\n",
      "subspecific genetic lineage\n",
      "trophic level\n",
      "relationship to oxygen\n",
      "known pathogenicity\n",
      "encoded traits\n",
      "observed biotic relationship\n",
      "air temperature regimen\n",
      "antibiotic regimen\n",
      "chemical mutagen\n",
      "fertilizer regimen\n",
      "fungicide regimen\n",
      "gravity\n",
      "growth hormone regimen\n",
      "growth media\n",
      "herbicide regimen\n",
      "humidity regimen\n",
      "mineral nutrient regimen\n",
      "non-mineral nutrient regimen\n",
      "pesticide regimen\n",
      "pH regimen\n",
      "radiation regimen\n",
      "rainfall regimen\n",
      "salt regimen\n",
      "standing water regimen\n",
      "tissue culture growth media\n",
      "watering regimen\n",
      "water temperature regimen\n",
      "mechanical damage\n",
      "chemical administration\n",
      "perturbation\n",
      "cell_type\n",
      "dev_stage\n",
      "organism part\n",
      "ploidy\n",
      "infect\n",
      "protocol\n",
      "sampling time point\n",
      "initial time point\n",
      "growth condition\n",
      "genotype\n",
      "sex\n",
      "age\n",
      "genetic modification\n",
      "phenotype\n",
      "cellular component\n",
      "individual\n",
      "disease staging\n",
      "immunoprecipitate\n",
      "replicate\n",
      "cultivar\n",
      "ecotype\n",
      "cell_line\n",
      "strain\n",
      "time\n",
      "dose\n",
      "chemical compound\n",
      "experimental factor 1\n",
      "experimental factor 2\n",
      "experimental factor 3\n",
      "experimental factor 4\n",
      "experimental factor 5\n",
      "block\n",
      "environmental stress\n",
      "environmental history\n",
      "ploidy\n",
      "number of replicons\n",
      "extrachromosomal elements\n",
      "estimated size\n",
      "sample volume or weight for DNA extraction\n",
      "collected_by\n",
      "collection date\n",
      "altitude\n",
      "geographic location (country and/or sea)\n",
      "geographic location (latitude)\n",
      "geographic location (longitude)\n",
      "geographic location (region and locality)\n",
      "identified_by\n",
      "depth\n",
      "broad-scale environmental context\n",
      "local environmental context\n",
      "elevation\n",
      "source material identifiers\n",
      "sample collection device or method\n",
      "sample material processing\n",
      "isolation and growth condition\n",
      "propagation\n",
      "amount or size of sample collected\n",
      "sample storage duration\n",
      "sample storage temperature\n",
      "sample storage location\n",
      "sampling time point\n",
      "plant structure\n",
      "plant developmental stage\n",
      "sampled age\n",
      "sample phenotype\n",
      "sample health state\n",
      "sample disease status\n",
      "sample disease stage\n",
      "sample wet mass\n",
      "sample dry mass\n",
      "sample height\n",
      "sample length\n",
      "growth facility\n",
      "sample capture status\n",
      "genotype\n",
      "genetic modification\n",
      "organism common name\n",
      "subspecific genetic lineage rank\n",
      "subspecific genetic lineage name\n",
      "biological status\n",
      "organism phenotype\n",
      "ancestral data\n",
      "source material description\n",
      "biotic relationship\n",
      "growth habit\n",
      "plant sex\n",
      "climate environment\n",
      "gaseous environment\n",
      "seasonal environment\n",
      "soil_taxonomic/FAO classification\n",
      "soil_taxonomic/local classification\n",
      "soil_taxonomic/local classification method\n",
      "soil type\n",
      "soil type method\n",
      "drainage classification\n",
      "soil texture measurement\n",
      "soil texture method\n",
      "soil water content\n",
      "soil pH\n",
      "plant growth medium\n",
      "rooting conditions\n",
      "culture rooting medium\n",
      "rooting medium macronutrients\n",
      "rooting medium micronutrients\n",
      "rooting medium organic supplements\n",
      "rooting medium carbon\n",
      "rooting medium regulators\n",
      "rooting medium solidifier\n",
      "rooting medium pH\n",
      "air temperature regimen\n",
      "antibiotic regimen\n",
      "chemical mutagen\n",
      "fertilizer regimen\n",
      "fungicide regimen\n",
      "gravity\n",
      "growth hormone regimen\n",
      "herbicide regimen\n",
      "humidity regimen\n",
      "mineral nutrient regimen\n",
      "non-mineral nutrient regimen\n",
      "pesticide regimen\n",
      "pH regimen\n",
      "radiation regimen\n",
      "rainfall regimen\n",
      "salt regimen\n",
      "standing water regimen\n",
      "watering regimen\n",
      "water temperature regimen\n",
      "plant treatment\n",
      "light regimen\n",
      "biotic regimen\n",
      "mechanical damage\n",
      "chemical administration\n",
      "perturbation\n"
     ]
    }
   ],
   "source": [
    "erc_list_name = [\"ERC000020.xml\", \"ERC000035.xml\",\"ERC000037.xml\"]\n",
    "erc_list = [\"checklist/ERCs/ERC000020.xml\", \"checklist/ERCs/ERC000035.xml\",\"checklist/ERCs/ERC000037.xml\"]\n",
    "output_list = []\n",
    "for index, path in enumerate(erc_list):\n",
    "    \n",
    "    xtree = et.parse(path)\n",
    "    xroot = xtree.getroot()\n",
    "    xml_cols = [\"name\", \"label\", \"description\", \"field_type\" ,\"value_type\" ,\"value_restrict\",\"mandatory\",\"multiplicity\", \"unit\", \"ERC\"]\n",
    "    xml_rows = []\n",
    "\n",
    "    for sets in xroot.iter('FIELD'):\n",
    "        print(sets.find('NAME').text)\n",
    "        r_name = sets.find('NAME').text if sets is not None else None   \n",
    "        r_label = sets.find('LABEL').text if sets is not None else None\n",
    "        r_description = sets.find('DESCRIPTION').text if sets.find('DESCRIPTION') is not None else None      \n",
    "        r_field_type = sets.find('FIELD_TYPE').find(\".//*\").tag if sets is not None else None  \n",
    "        r_value_type = sets.find('FIELD_TYPE').find(\".//*\").find(\".//*\").tag if sets.find('FIELD_TYPE').find(\".//*\").find(\".//*\") is not None else None  \n",
    "        r_value_restrict = sets.find('FIELD_TYPE').find(\".//*\").find(\".//*\").text if sets.find('FIELD_TYPE').find(\".//*\").find(\".//*\") is not None else None  \n",
    "        r_mandatory = sets.find('MANDATORY').text if sets is not None else None      \n",
    "        r_multiplicity = sets.find('MULTIPLICITY').text if sets is not None else None\n",
    "        r_unit = sets.find('UNITS').find('UNIT').text if sets.find('UNITS') is not None else None\n",
    "        xml_rows.append([r_name, r_label, r_description, r_field_type, r_value_type, r_value_restrict, r_mandatory, r_multiplicity, r_unit ,erc_list_name[index] ])    \n",
    "    xml_table= pd.DataFrame(xml_rows, columns= xml_cols)\n",
    "    output_list.append(xml_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list[0].to_csv(\"mapping_ERC000020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
